<!DOCTYPE html>
<html>
<head hexo-theme='https://volantis.js.org/#2.6.6'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
      <meta name="robots" content="noindex,follow">
    
  
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
    <title>归档：2018 - 挖掘之家</title>
  
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">

  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  

  <!-- import link -->
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  <div class="cover-wrapper">
    
      <cover class='cover  half'>
        <div class='cover-body'>
  <div class='a'>
    
      <img class='logo' src='https://i.loli.net/2020/07/11/fDHcmznoxPZgi2p.png'/>
    
    
    
  </div>
  <div id="binft" style="margin-top:20px"></div>
  <script>
    var binft = function (r) {
      function t() {
        return b[Math.floor(Math.random() * b.length)]
      }  
      function e() {
        return String.fromCharCode(94 * Math.random() + 33)
      }
      function n(r) {
        for (var n = document.createDocumentFragment(), i = 0; r > i; i++) {
          var l = document.createElement("span");
          l.textContent = e(), l.style.color = t(), n.appendChild(l)
        }
        return n
      }
      function i() {
        var t = o[c.skillI];
        c.step ? c.step-- : (c.step = g, c.prefixP < l.length ? (c.prefixP >= 0 && (c.text += l[c.prefixP]), c.prefixP++) : "forward" === c.direction ? c.skillP < t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = "backward", c.delay = a) : c.skillP > 0 ? (c.text = c.text.slice(0, -1), c.skillP--) : (c.skillI = (c.skillI + 1) % o.length, c.direction = "forward")), r.textContent = c.text, r.appendChild(n(c.prefixP < l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d)
      }
      var l = "",
      o = ["wengJJ个人技术小站"].map(function (r) {
      return r + ""
      }),
      a = 2,
      g = 1,
      s = 5,
      d = 75,
      b = ["rgb(110,64,170)", "rgb(150,61,179)", "rgb(191,60,175)", "rgb(228,65,157)", "rgb(254,75,131)", "rgb(255,94,99)", "rgb(255,120,71)", "rgb(251,150,51)", "rgb(226,183,47)", "rgb(198,214,60)", "rgb(175,240,91)", "rgb(127,246,88)", "rgb(82,246,103)", "rgb(48,239,130)", "rgb(29,223,163)", "rgb(26,199,194)", "rgb(35,171,216)", "rgb(54,140,225)", "rgb(76,110,219)", "rgb(96,84,200)"],
      c = {
        text: "",
        prefixP: -s,
        skillI: 0,
        skillP: 0,
        direction: "forward",
        delay: a,
        step: g
      };
      i()
      };
      binft(document.getElementById('binft'));
  </script>
  <div class='b' style="margin-top:20px">
    
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <input type="text" class="input u-search-input" placeholder="" />
          <i class="icon fas fa-search fa-fw"></i>
        </form>
      </div>
    
    <div class='menu navigation'>
      <ul class='cover-list-h'>
        
          
            <li>
              <a class="nav home"
                href="https://volantis.js.org/getting-started/"
                
                
                id="https:volantisjsorggetting-started">
                <i class='fas fa-book fa-fw'></i>文档
              </a>
            </li>
          
            <li>
              <a class="nav home"
                href="https://volantis.js.org/archives/"
                
                
                id="https:volantisjsorgarchives">
                <i class='fas fa-rss fa-fw'></i>博文
              </a>
            </li>
          
            <li>
              <a class="nav home"
                href="https://volantis.js.org/examples/"
                
                
                id="https:volantisjsorgexamples">
                <i class='fas fa-play-circle fa-fw'></i>示例
              </a>
            </li>
          
            <li>
              <a class="nav home"
                href="https://github.com/xaoxuu/hexo-theme-volantis/"
                
                  rel="external nofollow noopener noreferrer"
                
                
                  target="_blank"
                
                id="https:githubcomxaoxuuhexo-theme-volantis">
                <i class='fas fa-file-code fa-fw'></i>源码
              </a>
            </li>
          
            <li>
              <a class="nav home"
                href="https://volantis.js.org/contributors/"
                
                
                id="https:volantisjsorgcontributors">
                <i class='fas fa-handshake fa-fw'></i>鸣谢
              </a>
            </li>
          
        
      </ul>
    </div>
	
  </div>
</div>

      </cover>
    
    <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header shadow blur">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img class='logo' src='https://i.loli.net/2020/06/14/hMqVxO14JSg6z3Q.png'/>
          
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      

<div class='l_main'>
	
		
  <section class="post-list ">
    
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
    
    
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/30/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E5%85%88%E6%9C%89%E9%B8%A1or%E5%85%88%E6%9C%89%E8%9B%8B%EF%BC%9F%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E6%8B%86%E5%88%86%E4%B8%8E%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%E7%9A%84%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98/">
      数据矿工学习-先有鸡or先有蛋？浅谈数据拆分与特征缩放的顺序问题
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/Python/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>Python/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月30日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>前些天在 <strong><a href="https://github.com/MachineLearning100/100-Days-Of-ML-Code" target="_blank" rel="noopener">100-Days-Of-ML-Code</a> **上回答了一个关于数据拆分与特征缩放的顺序先后的一个issue，感觉挺有争议性的，故单独拎出来做下笔记说明。</strong>我的观点是：机器学习工程中，应该先进行数据划分，再进行特征缩放。**出于严谨性，本篇文章是从机器学习-数据挖掘方面进行数据拆分与特征缩放的顺序问题阐述，同时也欢迎大家一起讨论这个问题。</p>
<h1 id="问题阐述"><a href="#问题阐述" class="headerlink" title="问题阐述"></a>问题阐述</h1><p>关于数据拆分与特征缩放的顺序先后问题，一般会在工程中遇到，具体表现为：<br><strong>先数据拆分再特征缩放</strong> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler,MinMaxScaler </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=<span class="number">0.1</span>) </span><br><span class="line">sc = StandardScaler() </span><br><span class="line">X_train = sc.fit_transform(X_train) </span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>先数据缩放再数据拆分</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler,MinMaxScaler </span><br><span class="line">sc = StandardScaler() </span><br><span class="line">X_transform = sc.fit_transform(X) </span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X_transform,y,test_size=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="论点阐述"><a href="#论点阐述" class="headerlink" title="论点阐述"></a>论点阐述</h1><p>首先先来看下我们常用的两种 sklearn 上的特征缩放：<strong>StandardScaler()</strong>与<strong>MinMaxScaler()</strong><br><img src="https://i.loli.net/2020/08/29/Swdj8uivr2HL7Q1.png" alt=""><br>从图中可以看出StandardScalar涉及到了<strong>均值μ</strong>与<strong>标准差σ</strong>，而MinMaxScaler则涉及到了<strong>最大值max</strong>与<strong>最小值min</strong>。这些参数的取值都得考虑到<strong>全局样本</strong>的，什么意思呢？我们来看下两者的输出结果：<br><strong>先数据拆分再特征缩放</strong><br><img src="https://i.loli.net/2020/08/29/3p1NbgBruTw8IQY.png" alt=""><br><strong>先数据缩放再数据拆分</strong><br><img src="https://i.loli.net/2020/08/29/vzIewp9XNQRdu4q.png" alt=""><br>可以很明显看出，两种不同的操作顺序输出的数据是完全不同的，也就是说<strong>样本的分布是完全不同</strong>的(很重要！后面阐述要用到)，那这种差异性在现实工程中会有什么影响？要解答这个问题，首先我们首先需要了解<strong>fit_transform()</strong>方法，fit_transform()你可以理解为<strong>fit()</strong>方法和<strong>transform()</strong>方法的pipeline，进行特征缩放时我们的顺序是</p>
<ol>
<li>先fit获得相应的参数值（可以理解为获得特征缩放规则）</li>
<li>再用transform进行转换</li>
</ol>
<p>fit_transform方法就是先执行fit()方法再执行transform()方法，所以每执行一次就会采用新的<strong>特征缩放规则</strong>，我们可以将训练集的特征缩放规则应用到测试集上，可以将测试集的特征缩放规则应用到训练集上(不过一般很少这么做)，但是通过全部数据集(训练集+测试集)fit到的的特征缩放规则是<strong>没有模型训练意义</strong>的。 这里我们举一个例子：假设农业部要求我们用LR模型来对花类型进行分类，我们经过学习得到了一个LR模型，模型上线后，现在需要对新的花数据进行预测分类（此时我们可以把<strong>旧花数据看做训练集</strong>，<strong>新花数据看做测试集</strong>）：</p>
<ul>
<li>按照<strong>先数据拆分再特征缩放</strong>的做法是：先将旧花数据fit出特征缩放规则，接着将其transform到新花数据上，接着对<strong>应用旧花数据特征缩放规则</strong>的新花数据进行预测分类；</li>
<li>按照<strong>先数据缩放再数据拆分</strong>的做法是：将新旧花数据合并为一个总数据集，接着对总数据集进行fit_transform操作，最后再把新花数据切分出来进行预测分类；</li>
</ul>
<p><strong>重点！！！</strong><br>这时候问题来了，“我们经过学习得到了一个LR模型”，请问我们学习的数据是什么？旧花数据 OR 新旧花合并数据？<br>答案肯定是旧花数据啊，更为详细地讲，是<strong>应用旧花数据特征缩放规则的旧花数据</strong>，这时候第二种做法的问题就出来了，我们这个LR模型是根据<strong>应用旧花数据特征缩放规则的旧花数据</strong>的<strong>分布</strong>学习到的这条分类线<br><img src="https://i.loli.net/2020/08/29/anTWRmOQHG2ilrx.png" alt=""><br>而此时你却将这条分类线去应用在<strong>应用新旧花数据特征缩放规则的新花数据</strong>上，根据上方我们得到的论点“<strong>两种不同的操作顺序输出的样本的分布是完全不同</strong>”，两种完全不同的分布，你用根据<strong>其中一种分布</strong>学习得到分类线对<strong>另一种分布</strong>来说是<strong>完全没有使用意义</strong>的，因为两者根本可以说是根据不同的数据学习而来的，所以有些时候第二种做法效果可能会很好也可能会很糟糕，这就像你拿<strong>牛数据学习的LR模型去预测花的分类一样。</strong>而机器学习的前身就是统计学，而统计学的一个样本基本原则就是<strong>样本同质性（homogenetic）。</strong></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>iris = load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X, y = iris.data, iris.target</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>quantile_transformer = preprocessing.QuantileTransformer(random_state=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_trans = quantile_transformer.fit_transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_test_trans = quantile_transformer.transform(X_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.percentile(X_train[:, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>]) </span><br><span class="line">array([ <span class="number">4.3</span>,  <span class="number">5.1</span>,  <span class="number">5.8</span>,  <span class="number">6.5</span>,  <span class="number">7.9</span>])</span><br></pre></td></tr></table></figure>
<p>这里我贴的是sklearn的一段官方demo代码，可以看出sklearn的演示代码也是遵从<strong>先数据拆分再特征缩放的顺序</strong>进行的操作，先fit到X_train的特征缩放规则，再将其应用在X_test上，这也从一个小方面验证了我的观点吧(虽然我也不喜欢不严谨的举例论证方法)。所以综上所述，我的观点是在进行数据挖掘方面的工作时，在面对特征缩放环节时，应该<strong>先进行数据拆分再进行特征缩放环节。</strong> </p>
<p><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/23/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE7.4-SMO%E5%BA%8F%E5%88%97%E6%9C%80%E5%B0%8F%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/">
      数据矿工学习-《统计学习方法》思维导图7.4-SMO序列最小最优化算法
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>《统计学习方法-李航》/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月23日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>由Platt提出的SMO算法是支持向量机学习的一种快速算法，其特点为不断将原二次规划问题分解为只有两个变量的二次子规划问题，并对子问题进行解析求解，直到所有变量满足KKT条件为止。SVM是通过求得全局最优解来进行学习，SVM在面对大规模的训练样本时，效果往往不是很好·，SMO算法正是为了解决这个问题而提出的。至此SVM章节的相关内容就全部结束了（本节思维导图涉及较多的证明过程，各位可根据需要查阅）</p>
<p><strong>思维来自《统计学习方法》-李航</strong> </p>
<p><img src="https://i.loli.net/2020/08/29/PjLm9it3cN8kHlZ.png" alt=""></p>
<p><strong>凹脑图在线浏览地址：<a href="https://aonaotu.com/open/5b62a811b6dca20010cd3e74" target="_blank" rel="noopener">SMO序列最小最优化算法</a></strong><br><font color = red ><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/16/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-Python%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A5%9E%E5%99%A8pyecharts%E4%BD%BF%E7%94%A8%E7%BB%86%E5%88%99/">
      数据矿工学习-Python数据可视化神器pyecharts使用细则
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/Python/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>Python/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月16日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p><font color = red>注意</font>：<em>2018年的这篇文章是基于pyecharts-v0.5编写的，目前最新版本为v1.0，pyecharts-v1.0为船新的版本，详情请看<a href="https://github.com/pyecharts/pyecharts" target="_blank" rel="noopener">gallery.pyecharts.org</a></em></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们都知道python上的一款可视化工具<strong>matplotlib</strong>,而前些阵子做一个Spark项目的时候用到了百度开源的一个可视化JS工具-<strong>Echarts</strong>，可视化类型非常多，但是得通过导入js库在Java Web项目上运行，平时用Python比较多，于是就在想有没有Python与Echarts结合的轮子。Google后，找到一个国人开发的一个Echarts与Python结合的轮子：<strong><a href="https://github.com/pyecharts/pyecharts" target="_blank" rel="noopener">pyecharts</a></strong>，下面就来简述下<strong>pyecharts</strong>一些使用细则：</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>写这篇文章用的是Win环境，首先打开命令行(win+R),输入： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyecharts</span><br></pre></td></tr></table></figure>
<p>但笔者实测时发现，可能由于墙的原因，下载时会出现断线和速度过慢的问题导致下载失败，所以建议通过清华镜像来进行下载：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyecharts</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/08/29/FMvGKhC6f4ctYP8.png" alt=""> </p>
<p>出现上方的信息，即代表下载成功，我们可以来进行下一步的实验了！</p>
<h1 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h1><p>使用之前我们要强调一点：就是<strong>python2.x</strong>和<strong>python3.x</strong>的编码问题，在python3.x中你可以把它看做默认是<strong>unicode编码</strong>，但在python2.x中并不是默认的，原因就在它的bytes对象定义的混乱，而pyecharts是使用unicode编码来处理字符串和文件的，所以当你使用的是python2.x时，请务必在上方插入此代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br></pre></td></tr></table></figure>
<p>现在我们来开始正式使用pyecharts，这里我们直接使用官方的数据：</p>
<h2 id="柱状图-Bar"><a href="#柱状图-Bar" class="headerlink" title="柱状图-Bar"></a>柱状图-Bar</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//导入柱状图-Bar </span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br><span class="line">//设置行名 </span><br><span class="line">columns = [<span class="string">"Jan"</span>, <span class="string">"Feb"</span>, <span class="string">"Mar"</span>, <span class="string">"Apr"</span>, <span class="string">"May"</span>, <span class="string">"Jun"</span>, <span class="string">"Jul"</span>, <span class="string">"Aug"</span>, <span class="string">"Sep"</span>, <span class="string">"Oct"</span>, <span class="string">"Nov"</span>, <span class="string">"Dec"</span>] </span><br><span class="line">//设置数据 </span><br><span class="line">data1 = [<span class="number">2.0</span>, <span class="number">4.9</span>, <span class="number">7.0</span>, <span class="number">23.2</span>, <span class="number">25.6</span>, <span class="number">76.7</span>, <span class="number">135.6</span>, <span class="number">162.2</span>, <span class="number">32.6</span>, <span class="number">20.0</span>, <span class="number">6.4</span>, <span class="number">3.3</span>] </span><br><span class="line">data2 = [<span class="number">2.6</span>, <span class="number">5.9</span>, <span class="number">9.0</span>, <span class="number">26.4</span>, <span class="number">28.7</span>, <span class="number">70.7</span>, <span class="number">175.6</span>, <span class="number">182.2</span>, <span class="number">48.7</span>, <span class="number">18.8</span>, <span class="number">6.0</span>, <span class="number">2.3</span>] </span><br><span class="line">//设置柱状图的主标题与副标题 </span><br><span class="line">bar = Bar(<span class="string">"柱状图"</span>, <span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">//添加柱状图的数据及配置项 </span><br><span class="line">bar.add(<span class="string">"降水量"</span>, columns, data1, mark_line=[<span class="string">"average"</span>], mark_point=[<span class="string">"max"</span>, <span class="string">"min"</span>]) </span><br><span class="line">bar.add(<span class="string">"蒸发量"</span>, columns, data2, mark_line=[<span class="string">"average"</span>], mark_point=[<span class="string">"max"</span>, <span class="string">"min"</span>]) </span><br><span class="line">//生成本地文件（默认为.html文件） </span><br><span class="line">bar.render()</span><br></pre></td></tr></table></figure>

<h5 id="运行结果如下："><a href="#运行结果如下：" class="headerlink" title="运行结果如下："></a>运行结果如下：</h5><p><img src="https://i.loli.net/2020/08/29/O6KiVv5jBhJCw7y.png" alt=""> </p>
<p>简单的几行代码就可以将数据进行非常好看的可视化，而且还是动态的，在这里还是要安利一下jupyter，pyecharts在v0.1.9.2版本开始，在jupyter上直接调用实例（例如上方直接调用bar）就可以将图表直接表示出来，非常方便。</p>
<p>笔者数了数，目前pyecharts上的图表大概支持到二十多种，接下来，我们再用上方的数据来生成几个数据挖掘常用的图表示例：</p>
<h2 id="饼图-Pie"><a href="#饼图-Pie" class="headerlink" title="饼图-Pie"></a>饼图-Pie</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//导入饼图</span><br><span class="line">Pie <span class="keyword">from</span> pyecharts <span class="keyword">import</span> Pie </span><br><span class="line">//设置主标题与副标题，标题设置居中，设置宽度为<span class="number">900</span> </span><br><span class="line">pie = Pie(<span class="string">"饼状图"</span>, <span class="string">"一年的降水量与蒸发量"</span>,title_pos=<span class="string">'center'</span>,width=<span class="number">900</span>) //加入数据，设置坐标位置为【<span class="number">25</span>，<span class="number">50</span>】，上方的colums选项取消显示 </span><br><span class="line">pie.add(<span class="string">"降水量"</span>, columns, data1 ,center=[<span class="number">25</span>,<span class="number">50</span>],is_legend_show=<span class="literal">False</span>) </span><br><span class="line">//加入数据，设置坐标位置为【<span class="number">75</span>，<span class="number">50</span>】，上方的colums选项取消显示，显示label标签 pie.add(<span class="string">"蒸发量"</span>, columns, data2 ,center=[<span class="number">75</span>,<span class="number">50</span>],is_legend_show=<span class="literal">False</span>,is_label_show=<span class="literal">True</span>) </span><br><span class="line">//保存图表 </span><br><span class="line">pie.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/8UkvGxEjcbD1Wqe.png" alt=""></p>
<h2 id="箱体图-Boxplot"><a href="#箱体图-Boxplot" class="headerlink" title="箱体图-Boxplot"></a>箱体图-Boxplot</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//导入箱型图Boxplot </span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Boxplot </span><br><span class="line">boxplot = Boxplot(<span class="string">"箱形图"</span>, <span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">x_axis = [<span class="string">'降水量'</span>,<span class="string">'蒸发量'</span>] </span><br><span class="line">y_axis = [data1,data2] </span><br><span class="line">//prepare_data方法可以将数据转为嵌套的 [min, Q1, median (<span class="keyword">or</span> Q2), Q3, max] </span><br><span class="line">yaxis = boxplot.prepare_data(y_axis) </span><br><span class="line">boxplot.add(<span class="string">"天气统计"</span>, x_axis, _yaxis) </span><br><span class="line">boxplot.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/qex1dcZ4LyDb7BV.png" alt=""></p>
<h2 id="折线图-Line"><a href="#折线图-Line" class="headerlink" title="折线图-Line"></a>折线图-Line</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Line </span><br><span class="line">line = Line(<span class="string">"折线图"</span>,<span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">//is_label_show是设置上方数据是否显示 </span><br><span class="line">line.add(<span class="string">"降水量"</span>, columns, data1, is_label_show=<span class="literal">True</span>) </span><br><span class="line">line.add(<span class="string">"蒸发量"</span>, columns, data2, is_label_show=<span class="literal">True</span>) </span><br><span class="line">line.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/bUwqLN3Sfru8IsP.png" alt=""></p>
<h2 id="雷达图-Rader"><a href="#雷达图-Rader" class="headerlink" title="雷达图-Rader"></a>雷达图-Rader</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Radar radar = Radar(<span class="string">"雷达图"</span>, <span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">//由于雷达图传入的数据得为多维数据，所以这里需要做一下处理 </span><br><span class="line">radar_data1 = [[<span class="number">2.0</span>, <span class="number">4.9</span>, <span class="number">7.0</span>, <span class="number">23.2</span>, <span class="number">25.6</span>, <span class="number">76.7</span>, <span class="number">135.6</span>, <span class="number">162.2</span>, <span class="number">32.6</span>, <span class="number">20.0</span>, <span class="number">6.4</span>, <span class="number">3.3</span>]] </span><br><span class="line">radar_data2 = [[<span class="number">2.6</span>, <span class="number">5.9</span>, <span class="number">9.0</span>, <span class="number">26.4</span>, <span class="number">28.7</span>, <span class="number">70.7</span>, <span class="number">175.6</span>, <span class="number">182.2</span>, <span class="number">48.7</span>, <span class="number">18.8</span>, <span class="number">6.0</span>, <span class="number">2.3</span>]] </span><br><span class="line">//设置column的最大值，为了雷达图更为直观，这里的月份最大值设置有所不同 </span><br><span class="line">schema = [ (<span class="string">"Jan"</span>, <span class="number">5</span>), (<span class="string">"Feb"</span>,<span class="number">10</span>), (<span class="string">"Mar"</span>, <span class="number">10</span>), (<span class="string">"Apr"</span>, <span class="number">50</span>), (<span class="string">"May"</span>, <span class="number">50</span>), (<span class="string">"Jun"</span>, <span class="number">200</span>), (<span class="string">"Jul"</span>, <span class="number">200</span>), (<span class="string">"Aug"</span>, <span class="number">200</span>), (<span class="string">"Sep"</span>, <span class="number">50</span>), (<span class="string">"Oct"</span>, <span class="number">50</span>), (<span class="string">"Nov"</span>, <span class="number">10</span>), (<span class="string">"Dec"</span>, <span class="number">5</span>) ] </span><br><span class="line">//传入坐标 </span><br><span class="line">radar.config(schema) </span><br><span class="line">radar.add(<span class="string">"降水量"</span>,radar_data1) </span><br><span class="line">//一般默认为同一种颜色，这里为了便于区分，需要设置item的颜色 </span><br><span class="line">radar.add(<span class="string">"蒸发量"</span>,radar_data2,item_color=<span class="string">"#1C86EE"</span>) </span><br><span class="line">radar.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/4ZEjJ75MNwaVRf6.png" alt=""></p>
<h2 id="散点图-scatter"><a href="#散点图-scatter" class="headerlink" title="散点图-scatter"></a>散点图-scatter</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Scatter </span><br><span class="line">scatter = Scatter(<span class="string">"散点图"</span>, <span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">//xais_name是设置横坐标名称，这里由于显示问题，还需要将y轴名称与y轴的距离进行设置 </span><br><span class="line">scatter.add(<span class="string">"降水量与蒸发量的散点分布"</span>, data1,data2,xaxis_name=<span class="string">"降水量"</span>,yaxis_name=<span class="string">"蒸发量"</span>, yaxis_name_gap=<span class="number">40</span>) </span><br><span class="line">scatter.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/SMGXhcirBZ7v8FT.png" alt=""></p>
<h2 id="图表布局-Grid"><a href="#图表布局-Grid" class="headerlink" title="图表布局 Grid"></a>图表布局 Grid</h2><p>由于标题与图表是属于两个不同的控件，所以这里必须对下方的图表Line进行标题位置设置，否则会出现标题重叠的bug。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Grid </span><br><span class="line">//设置折线图标题位置 </span><br><span class="line">line = Line(<span class="string">"折线图"</span>,<span class="string">"一年的降水量与蒸发量"</span>,title_top=<span class="string">"45%"</span>) line.add(<span class="string">"降水量"</span>, columns, data1, is_label_show=<span class="literal">True</span>) </span><br><span class="line">line.add(<span class="string">"蒸发量"</span>, columns, data2, is_label_show=<span class="literal">True</span>) </span><br><span class="line">grid = Grid() </span><br><span class="line">//设置两个图表的相对位置 </span><br><span class="line">grid.add(bar, grid_bottom=<span class="string">"60%"</span>) </span><br><span class="line">grid.add(line, grid_top=<span class="string">"60%"</span>) </span><br><span class="line">grid.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/e7xHPzja1s5vBgS.png" alt=""></p>
<h2 id="两图结合-Overlap"><a href="#两图结合-Overlap" class="headerlink" title="两图结合 Overlap"></a><strong>两图结合 Overlap</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Overlap </span><br><span class="line">overlap = Overlap() </span><br><span class="line">bar = Bar(<span class="string">"柱状图-折线图合并"</span>, <span class="string">"一年的降水量与蒸发量"</span>) </span><br><span class="line">bar.add(<span class="string">"降水量"</span>, columns, data1, mark_point=[<span class="string">"max"</span>, <span class="string">"min"</span>]) bar.add(<span class="string">"蒸发量"</span>, columns, data2, mark_point=[<span class="string">"max"</span>, <span class="string">"min"</span>]) overlap.add(bar) </span><br><span class="line">overlap.add(line) </span><br><span class="line">overlap.render()</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/08/29/itufEskCZx4veln.png" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总结一下使用流程</p>
<ol>
<li>导入相关图表包</li>
<li>进行图表的基础设置，创建图表对象</li>
<li>利用add()方法进行数据输入与图表设置(可以使用print_echarts_options()来输出所以可配置项)</li>
<li>利用render()方法来进行图表保存</li>
</ol>
<p>pyecharts还有许多好玩的3D图表和地图图表，个人觉得地图图表是最好玩的，各位有兴趣可以去pyecharts的使用手册查看，有中文版的非常方便：<a href="http://pyecharts.org/#/?id=pyecharts" target="_blank" rel="noopener">pyecharts</a></p>
<hr>
<p>参考资料： pyecharts使用手册：<a href="http://pyecharts.org/#/?id=pyecharts" target="_blank" rel="noopener">http://pyecharts.org/#/?id=pyecharts</a> </p>
<p><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/10/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E7%8C%AE%E7%BB%99%E6%96%B0%E6%89%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/">
      数据矿工学习-这是一篇献给新手的深度学习综述
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>深度学习/论文简析</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月10日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇综述论文列举出了近年来深度学习的重要研究成果，从方法、架构，以及正则化、优化技术方面进行概述。这篇综述对于刚入门的深度学习新手是一份不错的参考资料，在形成基本学术界图景、指导文献查找等方面都能提供帮助。</p>
<p><strong>论文：Recent Advances in Deep Learning: An Overview</strong></p>
<p><img src="https://i.loli.net/2020/08/29/pdLv4BMIQJT1GYz.png" alt=""> </p>
<p>论文地址：<a href="https://arxiv.org/pdf/1807.08169v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.08169v1.pdf</a> </p>
<p><strong>摘要：</strong>深度学习是机器学习和人工智能研究的最新趋势之一。它也是当今最流行的科学研究趋势之一。深度学习方法为计算机视觉和机器学习带来了革命性的进步。新的深度学习技术正在不断诞生，超越最先进的机器学习甚至是现有的深度学习技术。近年来，全世界在这一领域取得了许多重大突破。由于深度学习正快度发展，导致了它的进展很难被跟进，特别是对于新的研究者。在本文中，我们将简要讨论近年来关于深度学习的最新进展。</p>
<h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>「深度学习」（DL）一词最初在 1986 被引入机器学习（ML），后来在 2000 年时被用于人工神经网络（ANN）。深度学习方法由多个层组成，以学习具有多个抽象层次的数据特征。DL 方法允许计算机通过相对简单的概念来学习复杂的概念。对于人工神经网络（ANN），深度学习（DL）（也称为分层学习（Hierarchical Learning））是指在多个计算阶段中精确地分配信用，以转换网络中的聚合激活。为了学习复杂的功能，深度架构被用于多个抽象层次，即非线性操作；例如 ANNs，具有许多隐藏层。用准确的话总结就是，深度学习是机器学习的一个子领域，它使用了多层次的非线性信息处理和抽象，用于有监督或无监督的特征学习、表示、分类和模式识别。</p>
<p>深度学习即表征学习是机器学习的一个分支或子领域，大多数人认为近代深度学习方法是从 2006 开始发展起来的。本文是关于最新的深度学习技术的综述，主要推荐给即将涉足该领域的研究者。本文包括 DL 的基本思想、主要方法、最新进展以及应用。</p>
<p>综述论文是非常有益的，特别是对某一特定领域的新研究人员。一个研究领域如果在不久的将来及相关应用领域中有很大的价值，那通常很难被实时跟踪到最新进展。现在，科学研究是一个很有吸引力的职业，因为知识和教育比以往任何时候都更容易分享和获得。对于一种技术研究的趋势来说，唯一正常的假设是它会在各个方面有很多的改进。几年前对某个领域的概述，现在可能已经过时了。</p>
<p>考虑到近年来深度学习的普及和推广，我们简要概述了深度学习和神经网络（NN），以及它的主要进展和几年来的重大突破。我们希望这篇文章将帮助许多新手研究者在这一领域全面了解最近的深度学习的研究和技术，并引导他们以正确的方式开始。同时，我们希望通过这项工作，向这个时代的顶级 DL 和 ANN 研究者们致敬：Geoffrey Hinton（Hinton）、Juergen Schmidhuber（Schmidhuber）、Yann LeCun（LeCun）、Yoshua Bengio（Bengio）和许多其他研究学者，他们的研究构建了现代人工智能（AI）。跟进他们的工作，以追踪当前最佳的 DL 和 ML 研究进展对我们来说也至关重要。 </p>
<p>在本论文中，我们首先简述过去的研究论文，对深度学习的模型和方法进行研究。然后，我们将开始描述这一领域的最新进展。我们将讨论深度学习（DL）方法、深度架构（即深度神经网络（DNN））和深度生成模型（DGM），其次是重要的正则化和优化方法。此外，用两个简短的部分对于开源的 DL 框架和重要的 DL 应用进行总结。我们将在最后两个章节（即讨论和结论）中讨论深入学习的现状和未来。</p>
<h1 id="2-相关研究"><a href="#2-相关研究" class="headerlink" title="2. 相关研究"></a>2. 相关研究</h1><p>在过去的几年中，有许多关于深度学习的综述论文。他们以很好的方式描述了 DL 方法、方法论以及它们的应用和未来研究方向。这里，我们简要介绍一些关于深度学习的优秀综述论文。 </p>
<p>Young 等人（2017）讨论了 DL 模型和架构，主要用于自然语言处理（NLP）。他们在不同的 NLP 领域中展示了 DL 应用，比较了 DL 模型，并讨论了可能的未来趋势。 </p>
<p>Zhang 等人（2017）讨论了用于前端和后端语音识别系统的当前最佳深度学习技术。 </p>
<p>Zhu 等人（2017）综述了 DL 遥感技术的最新进展。他们还讨论了开源的 DL 框架和其他深度学习的技术细节。</p>
<p>Wang 等人（2017）以时间顺序的方式描述了深度学习模型的演变。该短文简要介绍了模型，以及在 DL 研究中的突破。该文以进化的方式来了解深度学习的起源，并对神经网络的优化和未来的研究做了解读。</p>
<p>Goodfellow 等人（2016）详细讨论了深度网络和生成模型，从机器学习（ML）基础知识、深度架构的优缺点出发，对近年来的 DL 研究和应用进行了总结。 </p>
<p>LeCun 等人（2015）从卷积神经网络（CNN）和递归神经网络（RNN）概述了深度学习（DL）模型。他们从表征学习的角度描述了 DL，展示了 DL 技术如何工作、如何在各种应用中成功使用、以及如何对预测未来进行基于无监督学习（UL）的学习。同时他们还指出了 DL 在文献目录中的主要进展。</p>
<p>Schmidhuber（2015）从 CNN、RNN 和深度强化学习 (RL) 对深度学习做了一个概述。他强调了序列处理的 RNN，同时指出基本 DL 和 NN 的局限性，以及改进它们的技巧。 </p>
<p>Nielsen (2015) 用代码和例子描述了神经网络的细节。他还在一定程度上讨论了深度神经网络和深度学习。</p>
<p>Schmidhuber (2014) 讨论了基于时间序列的神经网络、采用机器学习方法进行分类，以及在神经网络中使用深度学习的历史和进展。 </p>
<p>Deng 和 Yu (2014) 描述了深度学习类别和技术，以及 DL 在几个领域的应用。 </p>
<p>Bengio (2013) 从表征学习的角度简要概述了 DL 算法，即监督和无监督网络、优化和训练模型。他聚焦于深度学习的许多挑战，例如：为更大的模型和数据扩展算法，减少优化困难，设计有效的缩放方法等。 </p>
<p>Bengio 等人 (2013) 讨论了表征和特征学习即深度学习。他们从应用、技术和挑战的角度探讨了各种方法和模型。 </p>
<p>Deng (2011) 从信息处理及相关领域的角度对深度结构化学习及其架构进行了概述。</p>
<p>Arel 等人 (2010) 简要概述了近年来的 DL 技术。 </p>
<p>Bengio (2009) 讨论了深度架构，即人工智能的神经网络和生成模型。 </p>
<p>最近所有关于深度学习（DL）的论文都从多个角度讨论了深度学习重点。这对 DL 的研究人员来说是非常有必要的。然而，DL 目前是一个蓬勃发展的领域。在最近的 DL 概述论文发表之后，仍有许多新的技术和架构被提出。此外，以往的论文从不同的角度进行研究。我们的论文主要是针对刚进入这一领域的学习者和新手。为此，我们将努力为新研究人员和任何对这一领域感兴趣的人提供一个深度学习的基础和清晰的概念。</p>
<h1 id="3-最新进展"><a href="#3-最新进展" class="headerlink" title="3. 最新进展"></a>3. 最新进展</h1><p>在本节中，我们将讨论最近从机器学习和人工神经网络 (ANN) 的中衍生出来的主要深度学习 (DL) 方法，人工神经网络是深度学习最常用的形式。</p>
<h2 id="3-1-深度架构的演变"><a href="#3-1-深度架构的演变" class="headerlink" title="3.1 深度架构的演变"></a>3.1 深度架构的演变</h2><p>人工神经网络 (ANN) 已经取得了长足的进步，同时也带来了其他的深度模型。第一代人工神经网络由简单的感知器神经层组成，只能进行有限的简单计算。第二代使用反向传播，根据错误率更新神经元的权重。然后支持向量机 (SVM) 浮出水面，在一段时间内超越 ANN。为了克服反向传播的局限性，人们提出了受限玻尔兹曼机（RBM），使学习更容易。此时其他技术和神经网络也出现了，如前馈神经网络 (FNN)、卷积神经网络 (CNN)、循环神经网络 (RNN) 等，以及深层信念网络、自编码器等。从那时起，为实现各种用途，ANN 在不同方面得到了改进和设计。</p>
<p>Schmidhuber (2014)、Bengio (2009)、Deng 和 Yu (2014)、Goodfellow 等人 (2016)、Wang 等人 (2017) 对深度神经网络 (DNN) 的进化和历史以及深度学习 (DL) 进行了详细的概述。在大多数情况下，深层架构是简单架构的多层非线性重复，这样可从输入中获得高度复杂的函数。</p>
<h1 id="4-深度学习方法"><a href="#4-深度学习方法" class="headerlink" title="4. 深度学习方法"></a>4. 深度学习方法</h1><p>深度神经网络在监督学习中取得了巨大的成功。此外，深度学习模型在无监督、混合和强化学习方面也非常成功。</p>
<h2 id="4-1-深度监督学习"><a href="#4-1-深度监督学习" class="headerlink" title="4.1 深度监督学习"></a>4.1 深度监督学习</h2><p>监督学习应用在当数据标记、分类器分类或数值预测的情况。LeCun 等人 (2015) 对监督学习方法以及深层结构的形成给出了一个精简的解释。Deng 和 Yu(2014) 提到了许多用于监督和混合学习的深度网络，并做出解释，例如深度堆栈网络 (DSN) 及其变体。Schmidthuber(2014) 的研究涵盖了所有神经网络，从早期神经网络到最近成功的卷积神经网络 (CNN)、循环神经网络 (RNN)、长短期记忆 (LSTM) 及其改进。</p>
<h2 id="4-2-深度无监督学习"><a href="#4-2-深度无监督学习" class="headerlink" title="4.2 深度无监督学习"></a>4.2 深度无监督学习</h2><p>当输入数据没有标记时，可应用无监督学习方法从数据中提取特征并对其进行分类或标记。LeCun 等人 (2015) 预测了无监督学习在深度学习中的未来。Schmidthuber(2014) 也描述了无监督学习的神经网络。Deng 和 Yu(2014) 简要介绍了无监督学习的深度架构，并详细解释了深度自编码器。</p>
<h2 id="4-3-深度强化学习"><a href="#4-3-深度强化学习" class="headerlink" title="4.3 深度强化学习"></a>4.3 深度强化学习</h2><p>强化学习使用奖惩系统预测学习模型的下一步。这主要用于游戏和机器人，解决平常的决策问题。Schmidthuber(2014) 描述了强化学习 (RL) 中深度学习的进展，以及深度前馈神经网络 (FNN) 和循环神经网络 (RNN) 在 RL 中的应用。Li(2017) 讨论了深度强化学习 (Deep Reinforcement Learning, DRL)、它的架构 (例如 Deep Q-Network, DQN) 以及在各个领域的应用。</p>
<p>Mnih 等人 (2016) 提出了一种利用异步梯度下降进行 DNN 优化的 DRL 框架。 </p>
<p>van Hasselt 等人 (2015) 提出了一种使用深度神经网络 (deep neural network, DNN) 的 DRL 架构。</p>
<h1 id="5-深度神经网络"><a href="#5-深度神经网络" class="headerlink" title="5. 深度神经网络"></a>5. 深度神经网络</h1><p>在本节中，我们将简要地讨论深度神经网络 (DNN)，以及它们最近的改进和突破。神经网络的功能与人脑相似。它们主要由神经元和连接组成。当我们说深度神经网络时，我们可以假设有相当多的隐藏层，可以用来从输入中提取特征和计算复杂的函数。Bengio(2009) 解释了深度结构的神经网络，如卷积神经网络(CNN)、自编码器 (AE) 等及其变体。Deng 和 Yu(2014) 详细介绍了一些神经网络架构，如 AE 及其变体。Goodfellow 等 (2016) 对深度前馈网络、卷积网络、递归网络及其改进进行了介绍和技巧性讲解。Schmidhuber(2014) 提到了神经网络从早期神经网络到最近成功技术的完整历史。</p>
<h2 id="5-1-深度自编码器"><a href="#5-1-深度自编码器" class="headerlink" title="5.1 深度自编码器"></a>5.1 深度自编码器</h2><p>自编码器 (AE) 是神经网络 (NN)，其中输出即输入。AE 采用原始输入，编码为压缩表示，然后解码以重建输入。在深度 AE 中，低隐藏层用于编码，高隐藏层用于解码，误差反向传播用于训练.。</p>
<h3 id="5-1-1-变分自编码器"><a href="#5-1-1-变分自编码器" class="headerlink" title="5.1.1 变分自编码器"></a>5.1.1 变分自编码器</h3><p>变分自动编码器 (VAE) 可以算作解码器。VAE 建立在标准神经网络上，可以通过随机梯度下降训练 (Doersch,2016)。</p>
<h3 id="5-1-2-多层降噪自编码器"><a href="#5-1-2-多层降噪自编码器" class="headerlink" title="5.1.2 多层降噪自编码器"></a>5.1.2 多层降噪自编码器</h3><p>在早期的自编码器 (AE) 中，编码层的维度比输入层小（窄）。在多层降噪自编码器 (SDAE) 中，编码层比输入层宽 (Deng and Yu, 2014)。</p>
<h3 id="5-1-3-变换自编码器"><a href="#5-1-3-变换自编码器" class="headerlink" title="5.1.3 变换自编码器"></a>5.1.3 变换自编码器</h3><p>深度自动编码器 (DAE) 可以是转换可变的，也就是从多层非线性处理中提取的特征可以根据学习者的需要而改变。变换自编码器 (TAE) 既可以使用输入向量，也可以使用目标输出向量来应用转换不变性属性，将代码引导到期望的方向 (Deng and Yu,2014)。</p>
<h2 id="5-2-深度卷积神经网络"><a href="#5-2-深度卷积神经网络" class="headerlink" title="5.2 深度卷积神经网络"></a>5.2 深度卷积神经网络</h2><p>四种基本思想构成了卷积神经网络 (CNN)，即：局部连接、共享权重、池化和多层使用。CNN 的第一部分由卷积层和池化层组成，后一部分主要是全连接层。卷积层检测特征的局部连接，池层将相似的特征合并为一个。CNN 在卷积层中使用卷积而不是矩阵乘法。</p>
<p>Krizhevsky 等人 (2012) 提出了一种深度卷积神经网络 (CNN) 架构，也称为 AlexNet，这是深度学习 (Deep Learning, DL) 的一个重大突破。网络由 5 个卷积层和 3 个全连接层组成。该架构采用图形处理单元 (GPU) 进行卷积运算，采用线性整流函数 (ReLU) 作为激活函数，用 Dropout 来减少过拟合。</p>
<p>Iandola 等人 (2016) 提出了一个小型的 CNN 架构，叫做「SqueezeNet」。</p>
<p>Szegedy 等人 (2014) 提出了一种深度 CNN 架构，名为 Inception。Dai 等人 (2017) 提出了对 Inception-ResNet 的改进。 </p>
<p>Redmon 等人 (2015) 提出了一个名为 YOLO (You Only Look Once) 的 CNN 架构，用于均匀和实时的目标检测。</p>
<p>Zeiler 和 Fergus (2013) 提出了一种将 CNN 内部激活可视化的方法。 </p>
<p>Gehring 等人 (2017) 提出了一种用于序列到序列学习的 CNN 架构。 </p>
<p>Bansal 等人 (2017) 提出了 PixelNet，使用像素来表示。 </p>
<p>Goodfellow 等人 (2016) 解释了 CNN 的基本架构和思想。Gu 等人 (2015) 对 CNN 的最新进展、CNN 的多种变体、CNN 的架构、正则化方法和功能以及在各个领域的应用进行了很好的概述。 </p>
<h3 id="5-2-1-深度最大池化卷积神经网络"><a href="#5-2-1-深度最大池化卷积神经网络" class="headerlink" title="5.2.1 深度最大池化卷积神经网络"></a>5.2.1 深度最大池化卷积神经网络</h3><p>最大池化卷积神经网络 (MPCNN) 主要对卷积和最大池化进行操作，特别是在数字图像处理中。MPCNN 通常由输入层以外的三种层组成。卷积层获取输入图像并生成特征图，然后应用非线性激活函数。最大池层向下采样图像，并保持子区域的最大值。全连接层进行线性乘法。在深度 MPCNN 中，在输入层之后周期性地使用卷积和混合池化，然后是全连接层。</p>
<h3 id="5-2-2-极深的卷积神经网络"><a href="#5-2-2-极深的卷积神经网络" class="headerlink" title="5.2.2 极深的卷积神经网络"></a>5.2.2 极深的卷积神经网络</h3><p>Simonyan 和 Zisserman(2014) 提出了非常深层的卷积神经网络 (VDCNN) 架构，也称为 VGG Net。VGG Net 使用非常小的卷积滤波器，深度达到 16-19 层。Conneau 等人 (2016) 提出了另一种文本分类的 VDCNN 架构，使用小卷积和池化。他们声称这个 VDCNN 架构是第一个在文本处理中使用的，它在字符级别上起作用。该架构由 29 个卷积层组成。</p>
<h2 id="5-3-网络中的网络"><a href="#5-3-网络中的网络" class="headerlink" title="5.3 网络中的网络"></a>5.3 网络中的网络</h2><p>Lin 等人 (2013) 提出了网络中的网络 (Network In Network,NIN)。NIN 以具有复杂结构的微神经网络代替传统卷积神经网络 (CNN) 的卷积层。它使用多层感知器 (MLPConv) 处理微神经网络和全局平均池化层，而不是全连接层。深度 NIN 架构可以由 NIN 结构的多重叠加组成。</p>
<h2 id="5-4-基于区域的卷积神经网络"><a href="#5-4-基于区域的卷积神经网络" class="headerlink" title="5.4 基于区域的卷积神经网络"></a>5.4 基于区域的卷积神经网络</h2><p>Girshick 等人 (2014) 提出了基于区域的卷积神经网络 (R-CNN)，使用区域进行识别。R-CNN 使用区域来定位和分割目标。该架构由三个模块组成：定义了候选区域的集合的类别独立区域建议，从区域中提取特征的大型卷积神经网络 (CNN)，以及一组类特定的线性支持向量机 (SVM)。 </p>
<h3 id="5-4-1-Fast-R-CNN"><a href="#5-4-1-Fast-R-CNN" class="headerlink" title="5.4.1 Fast R-CNN"></a>5.4.1 Fast R-CNN</h3><p>Girshick(2015) 提出了快速的基于区域的卷积网络 (Fast R-CNN)。这种方法利用 R-CNN 架构能快速地生成结果。Fast R-CNN 由卷积层和池化层、区域建议层和一系列全连接层组成。 </p>
<h3 id="5-4-2-Faster-R-CNN"><a href="#5-4-2-Faster-R-CNN" class="headerlink" title="5.4.2 Faster R-CNN"></a>5.4.2 Faster R-CNN</h3><p>Ren 等人 (2015) 提出了更快的基于区域的卷积神经网络 (Faster R-CNN)，它使用区域建议网络 (Region Proposal Network, RPN) 进行实时目标检测。RPN 是一个全卷积网络，能够准确、高效地生成区域建议 (Ren et al.，2015)。</p>
<h3 id="5-4-3-Mask-R-CNN"><a href="#5-4-3-Mask-R-CNN" class="headerlink" title="5.4.3 Mask R-CNN"></a>5.4.3 Mask R-CNN</h3><p>何恺明等人 (2017) 提出了基于区域的掩模卷积网络 (Mask R-CNN) 实例目标分割。Mask R-CNN 扩展了 R-CNN 的架构，并使用一个额外的分支用于预测目标掩模。</p>
<h3 id="5-4-4-Multi-Expert-R-CNN"><a href="#5-4-4-Multi-Expert-R-CNN" class="headerlink" title="5.4.4 Multi-Expert R-CNN"></a>5.4.4 Multi-Expert R-CNN</h3><p>.Lee 等人 (2017) 提出了基于区域的多专家卷积神经网络 (ME R-CNN)，利用了 Fast R-CNN 架构。ME R-CNN 从选择性和详尽的搜索中生成兴趣区域 (RoI)。它也使用 per-RoI 多专家网络而不是单一的 per-RoI 网络。每个专家都是来自 Fast R-CNN 的全连接层的相同架构。 </p>
<h2 id="5-5-深度残差网络"><a href="#5-5-深度残差网络" class="headerlink" title="5.5 深度残差网络"></a>5.5 深度残差网络</h2><p>He 等人 (2015) 提出的残差网络 (ResNet) 由 152 层组成。ResNet 具有较低的误差，并且容易通过残差学习进行训练。更深层次的 ResNet 可以获得更好的性能。在深度学习领域，人们认为 ResNet 是一个重要的进步。 </p>
<h3 id="5-5-1-Resnet-in-Resnet"><a href="#5-5-1-Resnet-in-Resnet" class="headerlink" title="5.5.1 Resnet in Resnet"></a>5.5.1 Resnet in Resnet</h3><p>Targ 等人 (2016) 在 Resnet in Resnet (RiR) 中提出将 ResNets 和标准卷积神经网络 (CNN) 结合到深层双流架构中。</p>
<h3 id="5-5-2-ResNeXt"><a href="#5-5-2-ResNeXt" class="headerlink" title="5.5.2 ResNeXt"></a>5.5.2 ResNeXt</h3><p>Xie 等人 (2016) 提出了 ResNeXt 架构。ResNext 利用 ResNets 来重复使用分割-转换-合并策略。</p>
<h2 id="5-6-胶囊网络"><a href="#5-6-胶囊网络" class="headerlink" title="5.6 胶囊网络"></a>5.6 胶囊网络</h2><p>Sabour 等人 (2017) 提出了胶囊网络 (CapsNet)，即一个包含两个卷积层和一个全连接层的架构。CapsNet 通常包含多个卷积层，胶囊层位于末端。CapsNet 被认为是深度学习的最新突破之一，因为据说这是基于卷积神经网络的局限性而提出的。它使用的是一层又一层的胶囊，而不是神经元。激活的较低级胶囊做出预测，在同意多个预测后，更高级的胶囊变得活跃。在这些胶囊层中使用了一种协议路由机制。Hinton 之后提出 EM 路由，利用期望最大化 (EM) 算法对 CapsNet 进行了改进。</p>
<h2 id="5-7-循环神经网络"><a href="#5-7-循环神经网络" class="headerlink" title="5.7 循环神经网络"></a>5.7 循环神经网络</h2><p>循环神经网络 (RNN) 更适合于序列输入，如语音、文本和生成序列。一个重复的隐藏单元在时间展开时可以被认为是具有相同权重的非常深的前馈网络。由于梯度消失和维度爆炸问题，RNN 曾经很难训练。为了解决这个问题，后来许多人提出了改进意见。 </p>
<p>Goodfellow 等人 (2016) 详细分析了循环和递归神经网络和架构的细节，以及相关的门控和记忆网络。</p>
<p>Karpathy 等人 (2015) 使用字符级语言模型来分析和可视化预测、表征训练动态、RNN 及其变体 (如 LSTM) 的错误类型等。 </p>
<p>J´ozefowicz 等人 (2016) 探讨了 RNN 模型和语言模型的局限性。</p>
<h3 id="5-7-1-RNN-EM"><a href="#5-7-1-RNN-EM" class="headerlink" title="5.7.1 RNN-EM"></a>5.7.1 RNN-EM</h3><p>Peng 和 Yao(2015) 提出了利用外部记忆 (RNN-EM) 来改善 RNN 的记忆能力。他们声称在语言理解方面达到了最先进的水平，比其他 RNN 更好。</p>
<h3 id="5-7-2-GF-RNN"><a href="#5-7-2-GF-RNN" class="headerlink" title="5.7.2 GF-RNN"></a>5.7.2 GF-RNN</h3><p>Chung 等 (2015) 提出了门控反馈递归神经网络 (GF-RNN)，它通过将多个递归层与全局门控单元叠加来扩展标准的 RNN。</p>
<h3 id="5-7-3-CRF-RNN"><a href="#5-7-3-CRF-RNN" class="headerlink" title="5.7.3 CRF-RNN"></a>5.7.3 CRF-RNN</h3><p>Zheng 等人 (2015) 提出条件随机场作为循环神经网络 (CRF-RNN)，其将卷积神经网络 (CNN) 和条件随机场 (CRF) 结合起来进行概率图形建模。</p>
<h3 id="5-7-4-Quasi-RNN"><a href="#5-7-4-Quasi-RNN" class="headerlink" title="5.7.4 Quasi-RNN"></a>5.7.4 Quasi-RNN</h3><p>Bradbury 等人 (2016) 提出了用于神经序列建模和沿时间步的并行应用的准循环神经网络 (QRNN)。 </p>
<h2 id="5-8-记忆网络"><a href="#5-8-记忆网络" class="headerlink" title="5.8 记忆网络"></a>5.8 记忆网络</h2><p>Weston 等人 (2014) 提出了问答记忆网络 (QA)。记忆网络由记忆、输入特征映射、泛化、输出特征映射和响应组成。</p>
<h3 id="5-8-1-动态记忆网络"><a href="#5-8-1-动态记忆网络" class="headerlink" title="5.8.1 动态记忆网络"></a>5.8.1 动态记忆网络</h3><p>Kumar 等人 (2015) 提出了用于 QA 任务的动态记忆网络 (DMN)。DMN 有四个模块:输入、问题、情景记忆、输出。</p>
<h2 id="5-9-增强神经网络"><a href="#5-9-增强神经网络" class="headerlink" title="5.9 增强神经网络"></a>5.9 增强神经网络</h2><p>Olah 和 Carter(2016) 很好地展示了注意力和增强循环神经网络，即神经图灵机 (NTM)、注意力接口、神经编码器和自适应计算时间。增强神经网络通常是使用额外的属性，如逻辑函数以及标准的神经网络架构。 </p>
<h3 id="5-9-1-神经图灵机"><a href="#5-9-1-神经图灵机" class="headerlink" title="5.9.1 神经图灵机"></a>5.9.1 神经图灵机</h3><p>Graves 等人 (2014) 提出了神经图灵机 (NTM) 架构，由神经网络控制器和记忆库组成。NTM 通常将 RNN 与外部记忆库结合。 </p>
<h3 id="5-9-2-神经-GPU"><a href="#5-9-2-神经-GPU" class="headerlink" title="5.9.2 神经 GPU"></a>5.9.2 神经 GPU</h3><p>Kaiser 和 Sutskever(2015) 提出了神经 GPU，解决了 NTM 的并行问题。 </p>
<h3 id="5-9-3-神经随机存取机"><a href="#5-9-3-神经随机存取机" class="headerlink" title="5.9.3 神经随机存取机"></a>5.9.3 神经随机存取机</h3><p>Kurach 等人 (2015) 提出了神经随机存取机，它使用外部的可变大小的随机存取存储器。</p>
<h3 id="5-9-4-神经编程器"><a href="#5-9-4-神经编程器" class="headerlink" title="5.9.4 神经编程器"></a>5.9.4 神经编程器</h3><p>Neelakantan 等人 (2015) 提出了神经编程器，一种具有算术和逻辑功能的增强神经网络。 5.9.5 神经编程器-解释器 Reed 和 de Freitas(2015) 提出了可以学习的神经编程器-解释器 (NPI)。NPI 包括周期性内核、程序内存和特定于领域的编码器。 </p>
<h2 id="5-10-长短期记忆网络"><a href="#5-10-长短期记忆网络" class="headerlink" title="5.10 长短期记忆网络"></a>5.10 长短期记忆网络</h2><p>Hochreiter 和 Schmidhuber(1997) 提出了长短期记忆 (Long short - Short-Term Memory, LSTM)，克服了循环神经网络 (RNN) 的误差回流问题。LSTM 是基于循环网络和基于梯度的学习算法，LSTM 引入自循环产生路径，使得梯度能够流动。 </p>
<p>Greff 等人 (2017) 对标准 LSTM 和 8 个 LSTM 变体进行了大规模分析，分别用于语音识别、手写识别和复调音乐建模。他们声称 LSTM 的 8 个变种没有显著改善，而只有标准 LSTM 表现良好。 </p>
<p>Shi 等人 (2016b) 提出了深度长短期记忆网络 (DLSTM)，它是一个 LSTM 单元的堆栈，用于特征映射学习表示。 </p>
<h3 id="5-10-1-批-归一化-LSTM"><a href="#5-10-1-批-归一化-LSTM" class="headerlink" title="5.10.1 批-归一化 LSTM"></a>5.10.1 批-归一化 LSTM</h3><p>Cooijmans 等人 (2016) 提出了批-归一化 LSTM (BN-LSTM)，它对递归神经网络的隐藏状态使用批-归一化。 </p>
<h3 id="5-10-2-Pixel-RNN"><a href="#5-10-2-Pixel-RNN" class="headerlink" title="5.10.2 Pixel RNN"></a>5.10.2 Pixel RNN</h3><p>van den Oord 等人 (2016b) 提出像素递归神经网络 (Pixel-RNN)，由 12 个二维 LSTM 层组成。 5.10.3 双向 LSTM W¨ollmer 等人 (2010) 提出了双向 LSTM(BLSTM) 的循环网络与动态贝叶斯网络 (DBN) 一起用于上下文敏感关键字检测。</p>
<h3 id="5-10-4-Variational-Bi-LSTM"><a href="#5-10-4-Variational-Bi-LSTM" class="headerlink" title="5.10.4 Variational Bi-LSTM"></a>5.10.4 Variational Bi-LSTM</h3><p>Shabanian 等人 (2017) 提出了变分双向 LSTM（Variational Bi-LSTM），它是双向 LSTM 体系结构的变体。Variational Bi-LSTM 使用变分自编码器 (VAE) 在 LSTM 之间创建一个信息交换通道，以学习更好的表征。 </p>
<h2 id="5-11-谷歌神经机器翻译"><a href="#5-11-谷歌神经机器翻译" class="headerlink" title="5.11 谷歌神经机器翻译"></a>5.11 谷歌神经机器翻译</h2><p>Wu 等人 (2016) 提出了名为谷歌神经机器翻译 (GNMT) 的自动翻译系统，该系统结合了编码器网络、解码器网络和注意力网络，遵循共同的序列对序列 (sequence-to-sequence) 的学习框架。 </p>
<h2 id="5-12-Fader-Network"><a href="#5-12-Fader-Network" class="headerlink" title="5.12 Fader Network"></a>5.12 Fader Network</h2><p>Lample 等人 (2017) 提出了 Fader 网络，这是一种新型的编码器-解码器架构，通过改变属性值来生成真实的输入图像变化。 </p>
<h2 id="5-13-超网络"><a href="#5-13-超网络" class="headerlink" title="5.13 超网络"></a>5.13 超网络</h2><p>Ha 等人 (2016) 提出的超网络（Hyper Networks）为其他神经网络生成权值，如静态超网络卷积网络、用于循环网络的动态超网络。 Deutsch(2018) 使用超网络生成神经网络。 </p>
<h2 id="5-14-Highway-Networks"><a href="#5-14-Highway-Networks" class="headerlink" title="5.14 Highway Networks"></a>5.14 Highway Networks</h2><p>Srivastava 等人 (2015) 提出了高速路网络（Highway Networks），通过使用门控单元来学习管理信息。跨多个层次的信息流称为信息高速路。</p>
<h3 id="5-14-1-Recurrent-Highway-Networks"><a href="#5-14-1-Recurrent-Highway-Networks" class="headerlink" title="5.14.1 Recurrent Highway Networks"></a>5.14.1 Recurrent Highway Networks</h3><p>Zilly 等人 (2017) 提出了循环高速路网络 (Recurrent Highway Networks，RHN)，它扩展了长短期记忆 (LSTM) 架构。RHN 在周期性过渡中使用了 Highway 层。 </p>
<h2 id="5-15-Highway-LSTM-RNN"><a href="#5-15-Highway-LSTM-RNN" class="headerlink" title="5.15 Highway LSTM RNN"></a>5.15 Highway LSTM RNN</h2><p>Zhang 等人 (2016) 提出了高速路长短期记忆 (high - Long short Memory, HLSTM) RNN，它在相邻层的内存单元之间扩展了具有封闭方向连接 (即 Highway) 的深度 LSTM 网络。 </p>
<h2 id="5-16-长期循环-CNN"><a href="#5-16-长期循环-CNN" class="headerlink" title="5.16 长期循环 CNN"></a>5.16 长期循环 CNN</h2><p>Donahue 等人 (2014) 提出了长期循环卷积网络 (LRCN)，它使用 CNN 进行输入，然后使用 LSTM 进行递归序列建模并生成预测。 </p>
<h2 id="5-17-深度神经-SVM"><a href="#5-17-深度神经-SVM" class="headerlink" title="5.17 深度神经 SVM"></a>5.17 深度神经 SVM</h2><p>Zhang 等人 (2015) 提出了深度神经 SVM(DNSVM)，它以支持向量机 (Support Vector Machine, SVM) 作为深度神经网络 (Deep Neural Network, DNN) 分类的顶层。 </p>
<h2 id="5-18-卷积残差记忆网络"><a href="#5-18-卷积残差记忆网络" class="headerlink" title="5.18 卷积残差记忆网络"></a>5.18 卷积残差记忆网络</h2><p>Moniz 和 Pal(2016) 提出了卷积残差记忆网络，将记忆机制并入卷积神经网络 (CNN)。它用一个长短期记忆机制来增强卷积残差网络。 </p>
<h2 id="5-19-分形网络"><a href="#5-19-分形网络" class="headerlink" title="5.19 分形网络"></a>5.19 分形网络</h2><p>Larsson 等人 (2016) 提出分形网络即 FractalNet 作为残差网络的替代方案。他们声称可以训练超深度的神经网络而不需要残差学习。分形是简单扩展规则生成的重复架构。 </p>
<h2 id="5-20-WaveNet"><a href="#5-20-WaveNet" class="headerlink" title="5.20 WaveNet"></a>5.20 WaveNet</h2><p>van den Oord 等人 (2016) 提出了用于产生原始音频的深度神经网络 WaveNet。WaveNet 由一堆卷积层和 softmax 分布层组成，用于输出。 Rethage 等人 (2017) 提出了一个 WaveNet 模型用于语音去噪。 <strong>5.21 指针网络</strong> Vinyals 等人 (2017) 提出了指针网络 (Ptr-Nets)，通过使用一种称为「指针」的 softmax 概率分布来解决表征变量字典的问题。 </p>
<h1 id="6-深度生成模型"><a href="#6-深度生成模型" class="headerlink" title="6. 深度生成模型"></a>6. 深度生成模型</h1><p>在本节中，我们将简要讨论其他深度架构，它们使用与深度神经网络类似的多个抽象层和表示层，也称为深度生成模型 (deep generate Models, DGM)。Bengio(2009) 解释了深层架构，例如 Boltzmann machine(BM) 和 Restricted Boltzmann Machines (RBM) 等及其变体。 </p>
<p>Goodfellow 等人 (2016) 详细解释了深度生成模型，如受限和非受限的玻尔兹曼机及其变种、深度玻尔兹曼机、深度信念网络 (DBN)、定向生成网络和生成随机网络等。 </p>
<p>Maaløe 等人（2016）提出了辅助的深层生成模型（Auxiliary Deep Generative Models），在这些模型中，他们扩展了具有辅助变量的深层生成模型。辅助变量利用随机层和跳过连接生成变分分布。 </p>
<p>Rezende 等人 (2016) 开发了一种深度生成模型的单次泛化。 </p>
<h2 id="6-1-玻尔兹曼机"><a href="#6-1-玻尔兹曼机" class="headerlink" title="6.1 玻尔兹曼机"></a>6.1 玻尔兹曼机</h2><p>玻尔兹曼机是学习任意概率分布的连接主义方法，使用最大似然原则进行学习。 </p>
<h2 id="6-2-受限玻尔兹曼机"><a href="#6-2-受限玻尔兹曼机" class="headerlink" title="6.2 受限玻尔兹曼机"></a>6.2 受限玻尔兹曼机</h2><p>受限玻尔兹曼机 (Restricted Boltzmann Machines, RBM) 是马尔可夫随机场的一种特殊类型，包含一层随机隐藏单元，即潜变量和一层可观测变量。 Hinton 和 Salakhutdinov(2011) 提出了一种利用受限玻尔兹曼机 (RBM) 进行文档处理的深度生成模型。</p>
<h2 id="6-3-深度信念网络"><a href="#6-3-深度信念网络" class="headerlink" title="6.3 深度信念网络"></a>6.3 深度信念网络</h2><p>深度信念网络 (Deep Belief Networks, DBN) 是具有多个潜在二元或真实变量层的生成模型。 Ranzato 等人 (2011) 利用深度信念网络 (deep Belief Network, DBN) 建立了深度生成模型进行图像识别。 </p>
<h2 id="6-4-深度朗伯网络"><a href="#6-4-深度朗伯网络" class="headerlink" title="6.4 深度朗伯网络"></a>6.4 深度朗伯网络</h2><p>Tang 等人 (2012) 提出了深度朗伯网络 (Deep Lambertian Networks，DLN)，它是一个多层次的生成模型，其中潜在的变量是反照率、表面法线和光源。DLNis 是朗伯反射率与高斯受限玻尔兹曼机和深度信念网络的结合。 </p>
<h2 id="6-5-生成对抗网络"><a href="#6-5-生成对抗网络" class="headerlink" title="6.5 生成对抗网络"></a>6.5 生成对抗网络</h2><p>Goodfellow 等人 (2014) 提出了生成对抗网络 (generate Adversarial Nets, GAN)，用于通过对抗过程来评估生成模型。GAN 架构是由一个针对对手（即一个学习模型或数据分布的判别模型）的生成模型组成。Mao 等人 (2016)、Kim 等人 (2017) 对 GAN 提出了更多的改进。 Salimans 等人 (2016) 提出了几种训练 GANs 的方法。 </p>
<h3 id="6-5-1-拉普拉斯生成对抗网络"><a href="#6-5-1-拉普拉斯生成对抗网络" class="headerlink" title="6.5.1 拉普拉斯生成对抗网络"></a>6.5.1 拉普拉斯生成对抗网络</h3><p>Denton 等人 (2015) 提出了一种深度生成模型 (DGM)，叫做拉普拉斯生成对抗网络 (LAPGAN)，使用生成对抗网络 (GAN) 方法。该模型还在拉普拉斯金字塔框架中使用卷积网络。 </p>
<h2 id="6-6-循环支持向量机"><a href="#6-6-循环支持向量机" class="headerlink" title="6.6 循环支持向量机"></a>6.6 循环支持向量机</h2><p>Shi 等人 (2016a) 提出了循环支持向量机 (RSVM)，利用循环神经网络 (RNN) 从输入序列中提取特征，用标准支持向量机 (SVM) 进行序列级目标识别。</p>
<h1 id="7-训练和优化技术"><a href="#7-训练和优化技术" class="headerlink" title="7. 训练和优化技术"></a>7. 训练和优化技术</h1><p>在本节中，我们将简要概述一些主要的技术，用于正则化和优化深度神经网络 (DNN)。 </p>
<h2 id="7-1-Dropout"><a href="#7-1-Dropout" class="headerlink" title="7.1 Dropout"></a>7.1 Dropout</h2><p>Srivastava 等人 (2014) 提出 Dropout，以防止神经网络过拟合。Dropout 是一种神经网络模型平均正则化方法，通过增加噪声到其隐藏单元。在训练过程中，它会从神经网络中随机抽取出单元和连接。Dropout 可以用于像 RBM (Srivastava et al.，2014) 这样的图形模型中，也可以用于任何类型的神经网络。最近提出的一个关于 Dropout 的改进是 Fraternal Dropout，用于循环神经网络 (RNN)。</p>
<h2 id="7-2-Maxout"><a href="#7-2-Maxout" class="headerlink" title="7.2 Maxout"></a>7.2 Maxout</h2><p>Goodfellow 等人 (2013) 提出 Maxout，一种新的激活函数，用于 Dropout。Maxout 的输出是一组输入的最大值，有利于 Dropout 的模型平均。 </p>
<h2 id="7-3-Zoneout"><a href="#7-3-Zoneout" class="headerlink" title="7.3 Zoneout"></a>7.3 Zoneout</h2><p>Krueger 等人 (2016) 提出了循环神经网络 (RNN) 的正则化方法 Zoneout。Zoneout 在训练中随机使用噪音，类似于 Dropout，但保留了隐藏的单元而不是丢弃。 </p>
<h2 id="7-4-深度残差学习"><a href="#7-4-深度残差学习" class="headerlink" title="7.4 深度残差学习"></a>7.4 深度残差学习</h2><p>He 等人 (2015) 提出了深度残差学习框架，该框架被称为低训练误差的 ResNet。 <strong>7.5 批归一化</strong> Ioffe 和 Szegedy(2015) 提出了批归一化，通过减少内部协变量移位来加速深度神经网络训练的方法。Ioffe(2017) 提出批重归一化，扩展了以前的方法。 </p>
<h2 id="7-6-Distillation"><a href="#7-6-Distillation" class="headerlink" title="7.6 Distillation"></a>7.6 Distillation</h2><p>Hinton 等人 (2015) 提出了将知识从高度正则化模型的集合 (即神经网络) 转化为压缩小模型的方法。 <strong>7.7 层归一化</strong> Ba 等人 (2016) 提出了层归一化，特别是针对 RNN 的深度神经网络加速训练，解决了批归一化的局限性。</p>
<h1 id="8-深度学习框架"><a href="#8-深度学习框架" class="headerlink" title="8. 深度学习框架"></a>8. 深度学习框架</h1><p>有大量的开源库和框架可供深度学习使用。它们大多数是为 Python 编程语言构建的。如 Theano、Tensorflow、PyTorch、PyBrain、Caffe、Blocks and Fuel 、CuDNN、Honk、ChainerCV、PyLearn2、Chainer,、torch 等。</p>
<h1 id="9-深度学习的应用"><a href="#9-深度学习的应用" class="headerlink" title="9. 深度学习的应用"></a>9. 深度学习的应用</h1><p>在本节中，我们将简要地讨论一些最近在深度学习方面的杰出应用。自深度学习 (DL) 开始以来，DL 方法以监督、非监督、半监督或强化学习的形式被广泛应用于各个领域。从分类和检测任务开始，DL 应用正在迅速扩展到每一个领域。 例如：</p>
<ul>
<li>图像分类与识别</li>
<li>视频分类</li>
<li>序列生成</li>
<li>缺陷分类</li>
<li>文本、语音、图像和视频处理</li>
<li>文本分类</li>
<li>语音处理</li>
<li>语音识别和口语理解</li>
<li>文本到语音生成</li>
<li>查询分类</li>
<li>句子分类</li>
<li>句子建模</li>
<li>词汇处理</li>
<li>预选择</li>
<li>文档和句子处理</li>
<li>生成图像文字说明</li>
<li>照片风格迁移</li>
<li>自然图像流形</li>
<li>图像着色</li>
<li>图像问答</li>
<li>生成纹理和风格化图像</li>
<li>视觉和文本问答</li>
<li>视觉识别和描述</li>
<li>目标识别</li>
<li>文档处理</li>
<li>人物动作合成和编辑</li>
<li>歌曲合成</li>
<li>身份识别</li>
<li>人脸识别和验证</li>
<li>视频动作识别</li>
<li>人类动作识别</li>
<li>动作识别</li>
<li>分类和可视化动作捕捉序列</li>
<li>手写生成和预测</li>
<li>自动化和机器翻译</li>
<li>命名实体识别</li>
<li>移动视觉</li>
<li>对话智能体</li>
<li>调用遗传变异</li>
<li>癌症检测</li>
<li>X 射线 CT 重建</li>
<li>癫痫发作预测</li>
<li>硬件加速</li>
<li>机器人</li>
</ul>
<p>等。</p>
<p>Deng 和 Yu(2014) 提供了 DL 在语音处理、信息检索、目标识别、计算机视觉、多模态、多任务学习等领域应用的详细列表。</p>
<p>使用深度强化学习 (Deep Reinforcement Learning, DRL) 来掌握游戏已经成为当今的一个热门话题。每到现在，人工智能机器人都是用 DNN 和 DRL 创建的，它们在战略和其他游戏中击败了人类世界冠军和象棋大师，从几个小时的训练开始。例如围棋的 AlphaGo 和 AlphaGo Zero。 </p>
<h1 id="10-讨论"><a href="#10-讨论" class="headerlink" title="10. 讨论"></a>10. 讨论</h1><p>尽管深度学习在许多领域取得了巨大的成功，但它还有很长的路要走。还有很多地方有待改进。至于局限性，例子也是相当多的。例如：Nguyen 等人表明深度神经网络（DNN）在识别图像时容易被欺骗。还有其他问题，如 Yosinski 等人提出的学习的特征可迁移性。Huang 等人提出了一种神经网络攻击防御的体系结构，认为未来的工作需要防御这些攻击。Zhang 等人则提出了一个理解深度学习模型的实验框架，他们认为理解深度学习需要重新思考和概括。</p>
<p>Marcus 在 2018 年对深度学习 (Deep Learning, DL) 的作用、局限性和本质进行了重要的回顾。他强烈指出了 DL 方法的局限性，即需要更多的数据，容量有限，不能处理层次结构，无法进行开放式推理，不能充分透明，不能与先验知识集成，不能区分因果关系。他还提到，DL 假设了一个稳定的世界，以近似方法实现，工程化很困难，并且存在着过度炒作的潜在风险。Marcus 认为 DL 需要重新概念化，并在非监督学习、符号操作和混合模型中寻找可能性，从认知科学和心理学中获得见解，并迎接更大胆的挑战。</p>
<h1 id="11-结论"><a href="#11-结论" class="headerlink" title="11. 结论"></a>11. 结论</h1><p>尽管深度学习（DL）比以往任何时候都更快地推进了世界的发展，但仍有许多方面值得我们去研究。我们仍然无法完全地理解深度学习，我们如何让机器变得更聪明，更接近或比人类更聪明，或者像人类一样学习。DL 一直在解决许多问题，同时将技术应用到方方面面。但是人类仍然面临着许多难题，例如仍有人死于饥饿和粮食危机, 癌症和其他致命的疾病等。我们希望深度学习和人工智能将更加致力于改善人类的生活质量，通过开展最困难的科学研究。最后但也是最重要的，愿我们的世界变得更加美好。</p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/08/100-Days-Of-ML-Code%20100%E5%A4%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%91%E6%88%98/">
      100-Days-Of-ML-Code 100天机器学习挑战
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>机器学习</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月8日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="100-Days-Of-ML-Code"><a href="#100-Days-Of-ML-Code" class="headerlink" title="100-Days-Of-ML-Code"></a><strong><a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">100-Days-Of-ML-Code</a></strong></h1><p><strong>ML网红Siraj Raval发起了一个名为：<a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">100-Days-Of-ML-Code</a>的挑战赛，意为鼓励同学们每天抽出点时间来学习机器学习，看看100天后你有了哪些进步</strong> <strong>目前Github上面最火爆的<a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">100-Days-Of-ML-Code</a>就是</strong><a href="https://github.com/Avik-Jain" target="_blank" rel="noopener">Avik-Jain</a><strong>的机器学习项目，超赞的配图，清晰的知识点梳理，是入门机器学习非常好的项目</strong> <strong>Github:</strong><a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">https://github.com/Avik-Jain/100-Days-Of-ML-Code</a> 目前和一群小伙伴已得到<a href="https://github.com/Avik-Jain" target="_blank" rel="noopener">Avik-Jain</a>的授权，正在着手对<a href="https://github.com/Avik-Jain" target="_blank" rel="noopener">Avik-Jain</a>/<strong><a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">100-Days-Of-ML-Code</a></strong>这个项目进行中文版本的编译，不单单只是编译，我们还会在原项目上提交完整的jupyter代码 <strong>Github:</strong><a href="https://github.com/MachineLearning100/100-Days-Of-ML-Code" target="_blank" rel="noopener">https://github.com/MachineLearning100/100-Days-Of-ML-Code</a> 这些对正在入门机器学习的同学们是非常好的入门教材，欢迎大家给原作者<a href="https://github.com/Avik-Jain" target="_blank" rel="noopener">Avik-Jain</a>和我们中文小组点Star！</p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/08/02/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE7.3-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E4%B8%8E%E6%A0%B8%E5%87%BD%E6%95%B0/">
      数据矿工学习-《统计学习方法》思维导图7.3-非线性支持向量机与核函数
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>《统计学习方法-李航》/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年8月2日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>前两篇我们看的是都是适应线性样本的支持向量机，那遇到非线性的分类问题呢？利用<strong>核技巧</strong>，就可以将线性分类的学习方法应用到非线性分类问题中去，将线性支持向量机拓展到非线性支持向量机，只需将线性支持向量机<strong>对偶形式中的内积</strong>换<strong>成核函数</strong>，接下来就来看下非线性支持向量机的思维导图：</p>
<p><strong>思维来自《统计学习方法》-李航</strong></p>
<p><img src="https://i.loli.net/2020/08/29/1yzgvq4mFbNAkSI.png" alt=""> </p>
<p><strong>凹脑图在线浏览地址：<a href="https://aonaotu.com/open/5b583a18d6f45d00135d984d" target="_blank" rel="noopener">非线性支持向量机</a></strong><br><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/07/24/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE7.2-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">
      数据矿工学习-《统计学习方法》思维导图7.2-线性支持向量机
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>《统计学习方法-李航》/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年7月24日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>上一章讲了线性可分支持向量机，但在实际工程中，样本数据往往是数据不可分的，此时就需要另一种学习器-线性支持向量机，又称线性不可分支持向量机，因为其适用范围更广，所以一般将其称为线性支持向量机，其学习策略为-<strong>软间隔最大化</strong>（区别于线性可分支持向量机的<strong>硬间隔最大化</strong>）： </p>
<p><strong>思维来自《统计学习方法》-李航</strong> </p>
<p><img src="https://i.loli.net/2020/08/29/ktaudOIsLqHcnXW.png" alt=""></p>
<p><strong>凹脑图在线浏览地址：<a href="https://aonaotu.com/open/5b4da5f7d6f45d00135d5cb5" target="_blank" rel="noopener">线性支持向量机</a></strong><br><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/07/23/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E6%A0%B7%E6%9C%AC%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%8D%B7%E7%A7%AF%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81%E8%AE%BA%E6%96%87-%E4%B8%AA%E4%BA%BA%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/">
      数据矿工学习-样本自适应的在线卷积稀疏编码论文-个人中文翻译
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>图像识别/论文简析</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年7月23日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://i.loli.net/2020/08/29/HFrb6MPyDSk3iph.png" alt=""> </p>
<p>论文地址 ： <a href="https://arxiv.org/abs/1804.10366" target="_blank" rel="noopener">https://arxiv.org/abs/1804.10366</a></p>
<p>文中的数学公式符号并不能很好的显示，采用普通字母代替，故带有一定的误差，建议数学公式的推导还是回归论文查看。</p>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>卷积稀疏编码（CSC）已被广泛用于图像和信号处理中的平移不变字典的学习。然而，现有的方法的可扩展性是有限的。在本文中，我们使用的不是样本共享的字典来卷积，而是使用<strong>样本**</strong>自适应<strong>**字典</strong>，其中每个过滤器是从数据中学习的一组基本滤波器的线性组合。这种灵活性允许捕获大量依赖于样本的模式，这在处理大型或高维数据集时特别有用。在计算上，所得到的模型可以通过在线学习来进行有效地学习。在大型数据集上的实验结果表明，所提出的方法优于现有的CSC算法，可以显著减少的时间和空间复杂度。  </p>
<h1 id="1-序言"><a href="#1-序言" class="headerlink" title="1.序言"></a>1.序言</h1><p>卷积稀疏编码目前已成功地应用在图像处理、信号处理和生物医学应用中。它与稀疏编码密切相关，但CSC的优点在于它的<strong>平移不变字典</strong>可以捕获<strong>信号</strong>和图像中常见的<strong>偏移局部模式</strong>。然后，每个数据样本由对应的代码卷积的字典中的一组滤波器的总和来表示。</p>
<p>传统的CSC算法在批处理模式下运行，采用O（<em>NK__^__2P+NKP</em> log <em>p</em>）时间和O（<em>NKP_）空间（其中<strong>n是样本数</strong>），<strong>k是滤波器的数目</strong>，<strong>p是维数</strong>。近年来，随着数据样本到达一定程度，样本的相关信息被压缩为小型的历史统计数据，并且模型被增量更新，已经提出了许多在线CSC算法拥有了更好的可扩展性。值得一提的是，最先进的OCSC算法具有更小的时间复杂度O（<em>K_</em>^__2P+KP</em> log P）和空间复杂度O（K^2P）。</p>
<p>然而，OCSC的复杂性仍然依赖于<strong>K</strong>，并且不能与大量的过滤器一起使用。因此，可以捕获的局部图案的数量是有限的，并且可能导致性能过低的情况出现，尤其是在高维数据集上更为严重。此外，使用更多的滤波器也导致了大量昂贵的卷积运算。RigaMunTi和SiRONI提出用<strong>可分离滤波器</strong>来近似地对学习过的滤波器进行后处理，使得卷积变得相对不那么昂贵。然而，由于学习和后处理是两个独立的过程，因此得到的滤波器可能不是最优的。此外，随着新样本的到来，这些独立的过滤器无法在线更新。 </p>
<p>CSC拓展的另一个方向是通过<strong>分布式计算</strong>（BotSekas＆TsisiKLIS，1997）。将数据和工作量分配到多台机器上，最近的<strong>共识**</strong>CSC算法**（ChoudHury等人，2017）可以处理更大型、更高维的数据集，例如视频、多光谱图像和光场图像。然而，关于CSC的计算需求只是通过共享运算平台解决，并没有真正地解决CSC的计算量问题。 </p>
<p>在本篇论文中，我们提出了通过从数据中学习的一组小型基础滤波器的自适应组合来近似大型滤波器。虽然标准CSC字典由所有样本共享，但我们建议每个样本都有自己的“个人”字典来补偿使用这些<strong>在线卷积稀疏编码</strong>与<strong>样本自适应**</strong>基滤波器<strong>而导致的灵活性降低的问题。以这种方式，表现效果可以保持相同，但参数数目却可以有效减少。计算上，这种结构还允许开发高效的在线学习算法。具体地，基础滤波器可以通过</strong>乘法器交替方向法（ADMM）<strong>更新（博伊德等人，2011），而代码和组合权重可以通过</strong>加速的近端算法**来学习（姚等人，2017）。在各种数据集上的广泛的实验结果表明，这种SCSC算法在时间和空间上都具有不错的效果，并且优于现有的批处理、在线和分布式CSC算法。 </p>
<p>论文的其余部分按如下方式组织。第2节简要回顾卷积稀疏编码。第3节描述了所提出的算法。实验结果在第4节中给出，最后一节给出了一些相关结论。  </p>
<h2 id="2-卷积稀疏编码综述-Review-Convolutional-Sparse-Coding"><a href="#2-卷积稀疏编码综述-Review-Convolutional-Sparse-Coding" class="headerlink" title="2.卷积稀疏编码综述 Review: Convolutional Sparse Coding"></a>2.卷积稀疏编码综述 Review: Convolutional Sparse Coding</h2><p>给定的样本<em>{x1，<strong>……，</strong>xn}_在R^P中，CSC学习一个<strong>移位不变字典</strong><em>D</em>∈R^_M__×__K_，其中列{_D</em>(: , <em>k</em>)} 表示k个滤波器。每个样本xi都被编码为<em>Z</em>i∈R^_P__×__K_，<em>k</em>th列是用滤波器<em>D</em>（:，<em>k</em>）卷积的代码。字典和代码是通过解决最优化问题一起学习得到的：</p>
<p><img src="https://i.loli.net/2020/08/29/nKdAz7alJmu2MU6.png" alt=""> </p>
<p>当第一项测量信号出现重构误差时，<strong>D</strong> = {<em>D</em> :||<em>D</em>(:,<em>k</em>) ||2 ≤ 1, ∀k = 1, . . . , K}保证了滤波器的归一化，β＞0是控制Zi’s稀疏性的正则化参数。</p>
<p>在空间域中执行（1）中的卷积。这需要<em>O（<strong>K</strong>PM）_时间，而且价格昂贵。相比之下，最近的CSC方法在频域上进行卷积，其取_O（K__P_log _p）_时间（Mallat，1999），并且对于M和P的典型选择更快，让x˜i ≡ <strong>F</strong>(xi)，<em>D</em>˜(:,_k</em>) ≡ <strong>F</strong>(<em>D</em>(:,<em>k</em>))和<em>Z</em>˜ i(:,<em>k</em>) ≡ <strong>F</strong>(Zi(:,<em>k</em>))成为xi ,<em>D</em>(:,<em>k</em>) and <em>Zi</em>(:,<em>k</em>)傅立叶变换后的对应。代码和滤波器以块坐标下降交替方式更新，如下：</p>
<p><img src="https://i.loli.net/2020/08/29/gAiKsY845qepFm7.png" alt=""><br><img src="https://i.loli.net/2020/08/29/4qSgRJXeOBLltQr.png" alt=""> </p>
<p>（2）和（3）都可以用<strong>乘法器交替方向法（ADMM）</strong>来求解（博伊德等人，2011）。随后，<em>{Z˜ i}<em>和</em>D˜_可以被转换回空间域，如Zi(:,_k</em>) = F^-1 (Z˜ i(:,<em>k</em>)) 和D(:,<em>k</em>)＝C(F^-1(<em>D˜</em>(:,k)))。</p>
<p>注意，虽然Zi’s（在空域中）是稀疏的，但是FFT变换后的的Z˜i’s 不是。 在推理上，给定学习字典<em>D</em>，测试样本x_ij_被重建为 ∑K/k=1 D(:, k) ∗ Zj (:, k)，其中<em>Z</em>j是得到的编码。</p>
<h3 id="2-1-可分离滤波器的后处理-Post-Processing-for-Separable-Filters"><a href="#2-1-可分离滤波器的后处理-Post-Processing-for-Separable-Filters" class="headerlink" title="2.1.可分离滤波器的后处理  Post-Processing for Separable Filters"></a>2.1.可分离滤波器的后处理  Post-Processing for Separable Filters</h3><p>由CSC获得的滤波器是不可分离的，随后的卷积可能是缓慢的。为了提高速度，它们可以通过可分离滤波器进行后处理和近似（RigaMaTi等人，2013；SiRONI等人，2015）。具体而言，学习的<em>D</em>是由_SW_近似的，其中S ∈ R^M×R包含R rank-1基础滤波器{<em>S</em>（：，1），…，<em>S</em>（：，<em>R</em>）}和W ∈ R^R×K包含<strong>组合权重</strong>。然而，这常常会导致性能低下。</p>
<h3 id="2-2-在线CSC-Online-CSC"><a href="#2-2-在线CSC-Online-CSC" class="headerlink" title="2.2. 在线CSC Online CSC"></a>2.2. 在线CSC Online CSC</h3><p><strong>在线CSC算法（OCSC）</strong>是最近提出的。在最后一次迭代中，给出了傅立叶变换的样本x˜t和字典D˜ t−1，得到了相应的{<em>Z</em>˜t, <em>Ut</em>}，如在（2）中得到的。下面的命题通过重新编写（3）使用较小的历史统计数据来更新D˜t 和_Vt_。 </p>
<p>命题1：Vt可以通过求解优化问题得到：<br><img src="https://i.loli.net/2020/08/29/W7SeJtlhNQofgmV.png" alt=""> </p>
<p>问题（4）可以用ADMM来解决。总的空间复杂度仅为O（<em>K</em>^2_P_），与<em>N</em>无关。此外，_H__t_和_G__t_可以进行增量更新。 </p>
<p>最近还提出了另外两个在线CSC的重新制定方案。Degraux提出的CSC方案通过在空间域上进行卷积，但速度较慢。Liu提出的CSC方案在频域中进行卷积，但需要昂贵的稀疏矩阵运算。  </p>
<h2 id="3-具有自适应字典的在线CSC-Online-CSC-with-Sample-Dependent-Dictionary"><a href="#3-具有自适应字典的在线CSC-Online-CSC-with-Sample-Dependent-Dictionary" class="headerlink" title="3.具有自适应字典的在线CSC Online CSC with Sample-Dependent Dictionary"></a>3.具有自适应字典的在线CSC Online CSC with Sample-Dependent Dictionary</h2><p>虽然OCSC在样本大小N的情况下可以很好地扩展，但它的空间复杂度仍然取决于滤波器数量K的平方。 这限制了可以使用的过滤器数量，并且可能影响性能。 受2.1节中可分离滤波器的思想的启发，我们通过用R基础滤波器来近似K滤波器以实现更多滤波器的学习，其中R&lt;K。 与通过<strong>后处理</strong>获得的可分离滤波器相比，我们建议在信号重建期间直接学习字典。此外，字典中的滤波器以样本自适应的方式从基本滤波器组合。</p>
<h3 id="3-1-问题描述-Problem-Formulation"><a href="#3-1-问题描述-Problem-Formulation" class="headerlink" title="3.1. 问题描述 Problem Formulation"></a>3.1. 问题描述 Problem Formulation</h3><p>回想一下，每一个<em>xi</em> in（1）都是由∑K/k=1 D(:, k) ∗ Zj (:, k)表示。设t B∈R^M×R，其中列{B(:,r)}是基础滤波器。我们建议将_xi_表示为：</p>
<p><img src="https://i.loli.net/2020/08/29/gkzlxsiEKLDo8Ue.png" alt=""> </p>
<p>这是依赖于样本的。如图所示，这允许Wi’进行独立学习（第3.3节）。这也导致更多的自适应模式被捕获，从而获得更好的性能（第4.4节）。 </p>
<p>卷积神经网络（CNN）最近研究了样本相关滤波器（Ja等人，2016）。从经验上看，这优于标准CNNs在单镜头学习，视频预测和图像去模糊这三个方面的表现。Jia使用专门设计的神经网络学习滤波器，不考虑CSC模型，而是将样本相关滤波器集成到CSC中。 </p>
<p>该词典还可以通过微调来适应单个样本。然而，当K很大时，学习初始共享字典仍然很昂贵。此外，如将在第4.2节中所示，所提出的方法将优于经验的微调。</p>
<h3 id="3-2-学习方法-Learning"><a href="#3-2-学习方法-Learning" class="headerlink" title="3.2. 学习方法 Learning"></a>3.2. 学习方法 Learning</h3><p>将（6）代入到CSC公式中（1），我们得到</p>
<p><img src="https://i.loli.net/2020/08/29/lgE5reDY9mFuQ42.png" alt=""> </p>
<p>由于<em>B</em>和<em>W</em>i在（8）中耦合在一起，这使得优化问题变得困难。下面的命题将B和Wi解耦。所有的证明都在附录中。</p>
<p><img src="https://i.loli.net/2020/08/29/gacCkPAQl2KhJEt.png" alt=""> </p>
<p>为了简化符号，我们用W表示W’1或W’2。通过在{Wi}上施加上述结构中的任一个，得到以下的优化问题：</p>
<p><img src="https://i.loli.net/2020/08/29/SsdUOjiBIX3pwar.png" alt=""> </p>
<p>在对样本x_j_进行推算时，可以通过解决(10)来获得相对应的（Wj，Zj）。</p>
<h3 id="3-3-在线学习算法解决（10）优化问题-Online-Learning-Algorithm-for-10"><a href="#3-3-在线学习算法解决（10）优化问题-Online-Learning-Algorithm-for-10" class="headerlink" title="3.3.在线学习算法解决（10）优化问题 Online Learning Algorithm for (10)"></a>3.3.在线学习算法解决（10）优化问题 Online Learning Algorithm for (10)</h3><p>正如在第2.2节中，我们提出了一个更好的可扩展性的在线算法。在<em>t</em>th迭代中，考虑</p>
<p><img src="https://i.loli.net/2020/08/29/7n1EBv4l5KQjDI3.png" alt=""> </p>
<p>设B˜(:, r) ≡ F(B(:, r))，其中B(:, r) ∈ R^M使用零填充为P维。</p>
<p>注意，通过重写上面的求和∑R/r=1 B(:, r) ∗( ∑K/k=1 <em>W</em>i(r, k)<em>Z</em>i(: , k))，可以将卷积的数量从k减少到r。 </p>
<p>下面的命题重写（11）并在频域中进行卷积。<br>命题3:问题(11)重写为：</p>
<p><img src="https://i.loli.net/2020/08/29/dJMS278auDTpvio.png" alt=""> </p>
<p>空域基础滤波器可以将B˜还原为B(:,r) = <strong>C</strong>(F^-1 (B˜(:,r)))。 </p>
<p><strong>3.3.1. B˜ t的获取</strong> <strong>OBTAINING B˜ t</strong> </p>
<p>从优化问题（12），可以通过求解子问题来获得B˜ t：</p>
<p><img src="https://i.loli.net/2020/08/29/N43E8lw2ZQbABgc.png" alt=""></p>
<p>其中V˜是辅助变量，这与（3）的形式相同。因此，类似于（4），B˜t可以通过下方优化问题得到：</p>
<p><img src="https://i.loli.net/2020/08/29/NZfTuw1EBhQPr2W.png" alt=""></p>
<p><strong>3.3.2.得到Wt和Zt  OBTAINING Wt AND Zt</strong> </p>
<p>随着XT的到来，我们将基础滤波器固定到在最后一次迭代中学习的B˜t−1，并从优化问题（12）获得（Wt，Zt）： </p>
<p><img src="https://i.loli.net/2020/08/29/Jatnwgq5CkDjhc7.png" alt=""></p>
<p>在CSC文献中，可以看出ADMM也可以用于求解（16）。虽然（2）中CSC的代码更新子问题是凸的，但问题（16）是非凸的，并且对于ADMM的现有收敛结果不适用。 </p>
<p>在本论文中，我们将使用非凸和不精确加速的近端梯度（NIAPG）算法（姚等人，2017）。这是最近的非凸问题的近似算法。由于（16）中W和Z的正则化器是独立的，所以两个块的近端步长W.R.T.可以分别执行：</p>
<p><img src="https://i.loli.net/2020/08/29/T7UW6HJupDxOK3B.png" alt=""> </p>
<p>如上方所示，这些单独的近端步骤可以很容易地计算。</p>
<p><strong>3.3.3.算法完善 COMPLETE ALGORITHM</strong> 整个过程将被称为“采样相关卷积稀疏编码（SCSC）”，在算法1中示出。它的空间复杂度为H(t) 和G（t），是O（R^2P）。其每次迭代时间复杂度为<em>O</em>（<em>RKP</em>+<em>RP</em> log_P_），其中O（<em>RKP_）项采用的是梯度计算，O（_RP</em> log <em>P</em>）是由于FFT/inverse FFT。表1比较了它的复杂性与其他在线和分布式CSC算法的复杂性。由此可见，SCSC具有较低的时间和空间复杂度。  </p>
<h1 id="4-实验-Experiments"><a href="#4-实验-Experiments" class="headerlink" title="4.实验 Experiments"></a>4.实验 Experiments</h1><p>我们在多个数据集上进行实验（表2）。Fruit和City是在CSC文献中常用的两个小型的图像数据集。我们使用默认训练和测试分割。图像的预处理包括转换为灰度、特征标准化、局部对比度归一化和边缘渐变。这两个数据集很小，在后面的实验中，我们还将使用两个更大的数据集，CIFAR10（Krizhevsky &amp; Hinton, 2009）和Flower（Nilsback &amp; Zisserman, 2008）。随后我们将滤波器大小M设为11×11，以及正则化参数。 </p>
<p><img src="https://i.loli.net/2020/08/29/JmogGZUiBItwhW9.png" alt=""><br><img src="https://i.loli.net/2020/08/29/Mfqmyuz1GKasOT4.png" alt=""> </p>
<p>为了评估学习字典的有效性，我们将主要考虑图像重建的任务。重建的图像质量通过测试峰值信噪比（PAPYANN等人，2017）来评估：</p>
<p><img src="https://i.loli.net/2020/08/29/P3yiFDNgMh1rzwe.png" alt=""> </p>
<p>其中X^j是测试集的X的重建。实验用不同的字典初始化重复五次。</p>
<h2 id="4-1-W的选择：W1与W2-Choice-of-W-W-1-versus-W-2"><a href="#4-1-W的选择：W1与W2-Choice-of-W-W-1-versus-W-2" class="headerlink" title="4.1.W的选择：W1与W2 Choice of W : W`1 versus W`2"></a>4.1.W的选择：W1与W2 Choice of W : W`1 versus W`2</h2><p>首先，我们研究命题2中W的选择。我们比较SCSC-L1，它使用W= W’1，而SCSC-L2，使用的是W＝W’2。实验是在Fruit和City数据集上进行的。滤波器K的数目设置为100。回看表1中的空间复杂度的结果，我们定义SCSC相对于OCSC的压缩比（使用相同的K）作为CR＝（K/R）^2。我们在{K／20，K／10，K／9，…，K／2，K}中改变R的值，同时相应的CR为{400, 100, 81，.…，1 }。 </p>
<p>结果如图1所示。可以看出，SCSC-L1是非常差的。图2（a）示出了在城市测试样本XJ上由K＝100和R＝10通过SCSC-L1获得的权重WJ（其他数据集上的结果是相似的）。可以看出，由于“1范数”引起的稀疏性，它的大部分条目都是零。表达能力严重受限，因为通常只使用一个基础滤波器来近似原始滤波器。另一方面，由SCSC-L2学习的WJ是稠密的并且具有更多的非零项（图2（b））。在续集中，我们只关注SCSC-L2，这将简单地表示为SCSC。</p>
<p><img src="https://i.loli.net/2020/08/29/ecE75rJlXiGs912.png" alt=""><br><img src="https://i.loli.net/2020/08/29/YmD9kUibHPFdE4n.png" alt=""></p>
<h2 id="4-2-样本自适应字典Sample-Dependent-Dictionary"><a href="#4-2-样本自适应字典Sample-Dependent-Dictionary" class="headerlink" title="4.2. 样本自适应字典Sample-Dependent Dictionary"></a>4.2. 样本自适应字典Sample-Dependent Dictionary</h2><p>在这个实验中，我们设置K＝100，并将SCSC与使用样本无关字典的下列算法进行比较：（i）SCSC（共享）：这是SCSC变体，其中所有Wi的In（5）都是相同的。其优化是基于交替最小化。（ii）通过张量分解（SET-TD）学习的可分离滤波器（SRONI等人，2015），这是基于后处理的（共享）字典，由OCSC学习的，如第2.1节所述；（iii）OCSC（王等人，2018）：最新的在线CSC算法。</p>
<p>结果如图3所示。可以看出，SCSC总是优于SCSC（共享）和SET-TD，当R＝10（对应于CR＝100）或以上时，SCSC优于OCSC。这表明使用依赖于样本的字典的优点。</p>
<p><img src="https://i.loli.net/2020/08/29/eZFVsODmvf3Npd7.png" alt=""> </p>
<p>接下来，我们与带精细调谐滤波器的OCSC进行比较，这也是样本自适应的。具体地，给定测试样本xj，我们首先从学习字典D获得（2）其代码Zj，然后通过使用新计算的Zj求解（3）来微调D。这是重复迭代的过程。我们设置OCSC的K等于SCSC的R，使这两种方法采取相同的空间复杂度（表1）。在SCSC中使用的K仍然是100。结果如图4所示。可以看出，虽然微调提高了OCSC的性能，但是这种产生样本自适应的滤波器的方法仍然比SCSC更差。</p>
<h2 id="4-3-多滤波器学习-Learning-with-More-Filters"><a href="#4-3-多滤波器学习-Learning-with-More-Filters" class="headerlink" title="4.3.多滤波器学习 Learning with More Filters"></a>4.3.多滤波器学习 Learning with More Filters</h2><p>召回SCSC允许使用更多的过滤器（即较大的K），因为其较低的时间和空间复杂度。在这一节中，我们证明了这可以发挥更好的性能。我们比较SCSC与最近两批和在线CSC方法，即基于切片的CSC（SBCSC）（PaPaun等人，2017）和OCSC。对于SCSC，我们设定R＝10为Fruit和City，R＝30为CIFAR-10和Flower。</p>
<p>图5显示了在不同K的测试PSNR。如图所示，较大的K总是对所有方法都有更好的性能。SCSC允许使用更大的K，因为它的内存占用小得多。例如，在CIFAR-10上，CR＝1024时K＝800；在Flower上，CR＝1600时K＝400。</p>
<p><img src="https://i.loli.net/2020/08/29/7ReqWmxIEudSaP2.png" alt=""></p>
<h2 id="4-4-与目前最新技术的比较-Comparison-with-the-State-of-the-Art"><a href="#4-4-与目前最新技术的比较-Comparison-with-the-State-of-the-Art" class="headerlink" title="4.4.与目前最新技术的比较 Comparison with the State-of-the-Art"></a>4.4.与目前最新技术的比较 Comparison with the State-of-the-Art</h2><p>首先，我们对Fruit和City的两个较小数据集进行实验，K = 100.我们为SCSC设置R = 10（即CR = 100）。 将其与批量CSC算法进行比较。 </p>
<p>图6显示了与时钟时间的测试PSNR的收敛性。也证明了在线CSC算法收敛更快，相比于批量CSC方法具有更好的PSNR。在在线方法中，SCSC具有与OCSC类似的PSNR，但是收敛得更快，并且占用更少的存储（CR＝100）。</p>
<p><img src="https://i.loli.net/2020/08/29/3YudEZQaGTb9VD2.png" alt=""> </p>
<p>接下来，我们对两个大数据集CIFAR-10和Flower进行实验。所有的批处理CSC算法和两个在线CSC算法OCDL-Degraux和OCDL-Liu并不能处理这样大的数据集。因此，我们只比较SCSC与OCSC。在CIFAR-10上，我们设定K＝300，相应的SCSC的CR为100。在Flower上，SCSC的K值仍为300。然而，OCSC只能使用k＝50，因为它的内存占用太多多。图7显示了测试PSNR的收敛性。在这两种情况下，SCSC显著优于OCSC。</p>
<p><img src="https://i.loli.net/2020/08/29/slHoC8ZcKReM91W.png" alt=""></p>
<h2 id="4-5-高维度数据-Higher-Dimensional-Data"><a href="#4-5-高维度数据-Higher-Dimensional-Data" class="headerlink" title="4.5.高维度数据 Higher-Dimensional Data"></a>4.5.高维度数据 Higher-Dimensional Data</h2><p>在这一节中，我们对具有大于两个维度的数据集进行实验。为了缓解大的内存问题Choudhury等人提出了分布式算法的使用。在这里，我们表明，SCSC可以在一台机器上有效地处理这些数据集。</p>
<p>实验在三个数据集（表3）中进行（CoudHury等人，2017）。视频数据集包含在机场记录的图像子序列。每个视频的长度为7，每个图像帧的大小为100×100。多光谱数据包含60×60块来自多光谱图像（覆盖31个波长）的真实世界物体和材料。光场数据包含60×60块在物体和场景上的光场图像。对于每个像素，光线是来自8×8不同的方向。（将滤波器的大小M设为11×11×11视频，11×11×31为多光谱，11×11×8×8为光场。</p>
<p><img src="https://i.loli.net/2020/08/29/KdZcvUpyDA82MXi.png" alt=""> </p>
<p>我们比较SCSC与OCSC和共识 CSC（CCSC）算法，K＝50。为了公平的比较，所有的方法只使用一台机器。我们不与批处理方法和两种在线方法（OCDL-Degraux和OCDL-Liu）进行比较，因为它们是不可扩展的（如在第4.4节中已经示出的）。</p>
<p>由于SCSC的内存占用小，我们在GTX 1080 TI GPU上运行这个实验。OCSC也在GPU上运行用于视频。然而，OCSC只能在CPU上运行多光谱和光场。CCSC在处理过程中需要访问所有的样本和代码，也只能在CPU 上运行。 </p>
<p>结果如表4所示。值得一提的是，SCSC是唯一可以处理整个视频、多光谱和光场数据集在一台机器上的算法。相比之下，CCSC只能处理最多30个视频样本、40个多光谱样本和35个光场样本。OCSC可以处理整个视频和多光谱，但是在使用整个光场数据集的2天内不能收敛。再一次表明SCSC优于OCSC和CCSC。 </p>
<p>至于收敛速度，SCSC是最快的。但是注意这只是作为参考，因为SCSC是在GPU上运行的，而其他的（除了视频上的OCSC）在CPU上运行。然而，这仍然表明SCSC的一个重要优点，即它的小内存占用可以受益于GPU的使用，而其他的算法则不能。</p>
<h2 id="4-6-图像去噪与修复-Image-Denoising-and-Inpainting"><a href="#4-6-图像去噪与修复-Image-Denoising-and-Inpainting" class="headerlink" title="4.6.图像去噪与修复 Image Denoising and Inpainting"></a>4.6.图像去噪与修复 Image Denoising and Inpainting</h2><p>在以前的实验中，学习字典的优势是通过重建干净的图像来证明的。在这一节中，我们进一步研究学习字典在两个应用：图像去噪和修复。使用Choudhury等人提供的十个测试图像。在去噪中，我们加入零均值和方差为0.01的高斯噪声对图像进行测试（平均输入PSNR为10dB）。在修复中，我们将随机子样本的50%像素作为0（平均输入PSNR为912dB）。随后我们使用二进制权重矩阵来掩盖缺失像素的位置。我们使用在第4.4节中从水果中吸取的过滤器。将SCSC与（批）SBCSC和（在线）OCSC进行比较。结果如表5所示。可以看出，由SCSC获得的PSNR始终高于其他算法。这表明，在图像重建中产生高PSNR的字典在其他图像处理应用中也可以发挥更好的性能。</p>
<p><img src="https://i.loli.net/2020/08/29/rWlLpDfuZwmtEkh.png" alt=""><br><img src="https://i.loli.net/2020/08/29/TzR7wg1ZNd5qODH.png" alt=""></p>
<h2 id="4-7-求解（16）：niAPG与ADMM-Solving-16-niAPG-vs-ADMM"><a href="#4-7-求解（16）：niAPG与ADMM-Solving-16-niAPG-vs-ADMM" class="headerlink" title="4.7. 求解（16）：niAPG与ADMM Solving (16): niAPG vs ADMM"></a>4.7. 求解（16）：niAPG与ADMM Solving (16): niAPG vs ADMM</h2><p>最后，我们比较了ADMM和niAPG在求解子问题（16）中的性能。我们使用来自City的训练样本xi。实验用不同的（Wi，Zi）初始化重复五次。图8显示了（16）目标随时间的收敛性。可见，niAPG具有快速收敛性，而ADMM不能收敛。图9显示了<img src="https://i.loli.net/2020/08/29/ZF9e2Wu5gwBE1Da.png" alt="">，它用迭代次数来衡量违反ADMM约束的情况。可以看出，违规不会达到零，这表明ADMM不收敛。  </p>
<h1 id="5-结论-Conclusion"><a href="#5-结论-Conclusion" class="headerlink" title="5.结论 Conclusion"></a>5.结论 Conclusion</h1><p>在本文中，我们提出了一种新的CSC扩展，其中每个样本都有自己的样本自适应的字典，由一组小的共享基滤波器构成。使用在线学习，该模型可以有效地更新，具有低的时间和空间复杂度。对包括大图像数据集和高维数据集在内的各种数据集的广泛实验都证明了它的效率和可扩展性。</p>
<p><img src="https://i.loli.net/2020/08/29/dNvUiFBetGSfT8r.png" alt=""> </p>
<p><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/07/23/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E6%A0%B7%E6%9C%AC%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%8D%B7%E7%A7%AF%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/">
      数据矿工学习-样本自适应的在线卷积稀疏编码论文简析
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>图像识别/论文简析</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年7月23日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>在瑞典斯德哥尔摩国际会展中心举行的国际机器学习大会(ICML)正在受到全世界科技界的关注。来自国内人工智能企业队代表第四范式的姚权铭与来自香港科技大学的研究者提出的“Online Convolutional Sparse Coding with Sample-Dependent Dictionary：样本自适应的在线卷积稀疏编码”，入选了ICML 2018中选论文榜单。 </p>
<p>首先我们先通过思维导图来简要了解下这篇SCSC论文的整体结构：</p>
<p><img src="https://i.loli.net/2020/08/29/wonuO3Zhxc2XePm.png" alt=""></p>
<h1 id="WHAT"><a href="#WHAT" class="headerlink" title="WHAT"></a><strong>WHAT</strong></h1><p><strong>SCSC是什么？</strong></p>
<p><img src="https://i.loli.net/2020/08/29/jGkAUTQ9agYWlqo.png" alt=""> </p>
<p><strong>卷积稀疏编码（**</strong><em>CSC</em><strong>**）</strong>已被广泛用于图像和信号处理中的<strong>平移不变字典(**</strong><em>sample-dependent dictionary</em><strong>**)</strong>的学习。不同于传统的CSC算法使用由<strong>所有样本共享的字典</strong>来卷积，此篇论文中的SCSC使用的是<strong>样本自适应的字典</strong>，其中每个过滤器是从数据中学习的一组<strong>基本滤波器</strong>的<strong>线性组合</strong>。这种增加的灵活性允许捕获大量依赖于样本的模式，这在处理<strong>大型</strong>或<strong>高维</strong>数据集时特别有用。在计算上，所得到的模型可以通过<strong>在线学习</strong>有效地学习。在大量的数据集上的实验结果表明，所提出的方法优于现有的CSC算法，具有显著减少的<strong>时间</strong>和<strong>空间复杂度</strong>。  </p>
<h1 id="WHY"><a href="#WHY" class="headerlink" title="WHY"></a><strong>WHY</strong></h1><p>*<em>SCSC的优势在哪里？ *</em></p>
<p>与目前的最新的CSC进行对比，SCSC的优势主要体现在三个方面: </p>
<p><strong>1、数据集的大小</strong> </p>
<p>小样本数据集： 在小数据集的实验中，论文中将<strong>SCSC</strong>与<strong>批量CSC方法</strong>进行比较(<em>包括<strong>DeconvNet</strong>、<strong>fast CSC</strong>、<strong>fast and flexible CSC</strong>等</em>)，其中也包括着与<strong>SCSC</strong>一样采用在线方法的<strong>OCSC</strong>，实验的检验指标采用的是PSNR(<em>峰值信噪比__Peak Signal to Noise Ratio</em>)，得到的结果如下图：</p>
<p><img src="https://i.loli.net/2020/08/29/RK8bkpLyzmABEZd.png" alt=""> </p>
<p>上方的图表现了各种CSC方法在时钟时间(<em>clock time</em>)下的PSNR收敛性，实验表明了小数据集条件下，<strong>在线CSC方法</strong>比<strong>批量CSC方法</strong>收敛的更快，具有更好的PSNR，而同样是在线方法的OCSC,SCSC虽然与OCSC具有类似的PSNR，但SCSC收敛的更快。</p>
<p>大样本数据集： 而在大数据集实验中，所有的批处理CSC算法和两个在线CSC算法<strong>OCDL DEGRAUX</strong>和<strong>OCDLLU</strong>不能处理这样大的数据集。因此，我们只比较<strong>SCSC</strong>与<strong>OCSC</strong>，比较的结果如下：</p>
<p><img src="https://i.loli.net/2020/08/29/UADwHvniRyZ3MK1.png" alt=""> </p>
<p>在CIFAR-10数据集上，我们设定<strong>SCSC</strong>和<strong>OCSC</strong>的<strong>K(<em>滤波器数量</em>)</strong>＝300。在Flower数据集上，SCSC的K值仍为300。然而，OCSC只能使用k＝50，因为它的内存占用大得多。图7显示了测试的PSNR的收敛性。在这两种情况下，<strong>SCSC</strong>显著优于<strong>OCSC</strong>。</p>
<p><strong>2、高维度数据集下的表现</strong> </p>
<p>高维数组采用的是三种数据集：<strong>视频数据集</strong>、<strong>光谱数据集</strong>、<strong>光场数据集</strong>。研究人员将<strong>SCSC</strong>与<strong>OCSC</strong>和<strong>CousSUS CSC（CCSC）</strong>作对比，为了公平的比较，所有的方法只使用一台机器。值得一提的是，由于SCSC的内存占用小，实验人员可以在GTX 1080 TI GPU上运行这个实验。OCSC也在GPU上运行用于视频。然而，OCSC只能在CPU上运行多光谱和光场。CCSC在处理过程中需要访问所有的样本和代码，只能在CPU 上运行，实验的结果如下图：</p>
<p><img src="https://i.loli.net/2020/08/29/DXBQPFilApKWjwx.png" alt=""> </p>
<p>根据论文中的实验结果显示，SCSC是<strong>唯一</strong>的可以处理整个视频，多光谱和光场数据集在<strong>一台机器</strong>上的方法。相比之下，CCSC只能处理最多30个视频样本、40个多光谱样本和35个光场样本。OCSC可以处理整个视频和多光谱，但是在使用整个光场数据集的2天内不能收敛。 </p>
<p>至于<strong>速度</strong>，如Table 4所示SCSC的速度是最快的。但是值得注意的是，这仅仅只是作为参考，因为SCSC是在GPU上运行的，而其他的（_除了视频<strong>数据集</strong>上的OCSC_）都是在CPU上运行。然而，这仍然表明SCSC的一个重要优点，即它的小内存占用可以受益于GPU的使用，而其他的则不能。</p>
<p><strong>3、图像的去噪与修复</strong></p>
<p>在以前的实验中，学习字典的优势是通过<strong>重建干净的图像</strong>来证明的。此篇论文中研究人员进一步研究学习字典中的两个应用：<strong>图像去噪</strong>和<strong>修复</strong>。研究人员使用<strong>SCSC</strong>与<strong>（批**</strong>处理CSC<strong>**）SBCSC</strong>和<strong>（在线）OCSC</strong>进行比较。结果如表5所示:</p>
<p><img src="https://i.loli.net/2020/08/29/Wv8AaCNXw1Z3ihm.png" alt=""> </p>
<p>可以看出，由SCSC获得的PSNR始终高于其他方法。这同时也表明，在图像重建中产生高PSNR的字典也在可以使其他图像处理应用发挥更好的性能。  </p>
<h1 id="HOW"><a href="#HOW" class="headerlink" title="HOW"></a><strong>HOW</strong></h1><p>*<em>SCSC的使用细则 *</em></p>
<p>论文中提出的<strong>样本自适应的卷积稀疏编码</strong>(SCSC)主要解决<strong>传统卷积稀疏编码(CSC)</strong>不能适用于高维度数据(P表示)和较多过滤器(K表示)的问题；SCSC的核心有两点：</p>
<p><img src="https://i.loli.net/2020/08/29/PjGLF9IM26SqewA.png" alt=""> </p>
<p>(a)首先将CSC过滤器用两部分表示，第一部分是<strong>基础滤波器(<em>base filters</em>)</strong>所有样本共享，第二部分是<strong>样本自适应系数(<em>sample-dependent weights</em>)</strong>每个样本单独学习。这样一来，和标准CSC比较，SCSC方法中并没有全局的滤波器，而是对每个样本从一堆<strong>基础滤波器</strong>中通过<strong>样本自适应系数</strong>组合出来自己的<strong>滤波器</strong>。</p>
<p>(b)基于以上模型，只有<strong>基础滤波器</strong>是依赖于<strong>全部数据</strong>的。方法的第二点在于我们使用在线学习的方法去<strong>快速</strong>并且<strong>小内存</strong>的学习<strong>基础滤波器</strong>。</p>
<p>具体的<strong>SCSC学习算法</strong>如下：</p>
<p><img src="https://i.loli.net/2020/08/29/RiAymcKHN2X4Cos.png" alt=""><br><img src="https://i.loli.net/2020/08/29/bvsYJMNaKEj1tig.png" alt=""></p>
<h1 id="DICUSS"><a href="#DICUSS" class="headerlink" title="DICUSS"></a><strong>DICUSS</strong></h1><p>*<em>关于SCSC的讨论与思考 *</em></p>
<p>随着<strong>CNN(<em>卷积神经网络</em>)</strong>在图像识别的效果越来越好，CNN越来越受AI学者的青睐，越来越多的应用也开始尝试采用CNN方法，但是，随着对CNN的尝试和研究的深入，它的<strong>不可解释性</strong>以及实验的<strong>不可复制重复的问题</strong>变的越来越严重，CNN是个黑盒魔法已几乎成为共识，相比与处理图像分类问题的CNN，CSC是一个线<strong>性卷积的无监督的学习的方法</strong>。CSC模型更<strong>简单</strong>，更<strong>直观</strong>容易<strong>分析理解</strong>。因此，最近一些机器学习&amp;机器视觉大牛(e.g. Michael Elad - 稀疏编码的创始人之一)开始尝试着用CSC解决应用问题和理解CNN，在应用层面上，医疗/生物图片数据，例如脑磁图(<em>Magnetoencephalography, MEG</em>)，(电子显微镜获得)，还有频谱(<em>hyperspectral image</em>)和光场(<em>light field</em>)数据上都使用CSC取得了非常不错的成果。 </p>
<p>同时研究人员也表示，未来将结合<strong>自适应在线卷积稀疏编码SCSC</strong>和<strong>神经网络模型</strong>的优势，将样本自适应的idea应用到卷积神经网络模型中。这将<strong>增加</strong>神经网络<strong>迁移学习</strong>的能力同时<strong>减少</strong>其所需要的<strong>计算量</strong>，使得这些网络在<strong>高维度低样本</strong>数据上也适用。 </p>
<p>论文链接：<a href="https://arxiv.org/pdf/1804.10366.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1804.10366.pdf</a> </p>
<p><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
        
          <div class='post-wrapper'>
            <article class="post white-box shadow reveal ">
  


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h2 class="title">
    <a href="/2018/07/18/%E6%95%B0%E6%8D%AE%E7%9F%BF%E5%B7%A5%E5%AD%A6%E4%B9%A0-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE7.1-%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">
      数据矿工学习-《统计学习方法》思维导图7.1-线性可分支持向量机
    </a>
  </h2>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://xaoxuu.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png">
    <p>Mr. X</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>《统计学习方法-李航》/数据挖掘</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年7月18日</p>
  </a>
</div>

            
          
            
              

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


  <section class="article typo">
    <div class="article-entry" itemprop="articleBody">
      
        <p>在机器学习的学习之路上，SVM是ML童鞋们在分类问题上一定会遇到的一个学习方法，SVM这一章将SVM按训练数据的<strong>线性可分性</strong>分为由简到繁分为三种模型：<strong>线性可分支持向量机(linner support vector machine in linearly separable case)</strong>、<strong>线性支持向量机(linear support vector machine)</strong>以及<strong>非线性支持向量机(non-linear support vector)</strong>。在实际工程中，面对不同规模的数据集时，在小型数据集上，SVM有时仅需<strong>小量</strong>的训练数据，就可以得到比较好的训练结果，而这正是因为SVM的特性-支持向量，下面通过思维导图先简单介绍下SVM：</p>
<p><img src="https://i.loli.net/2020/08/29/ekThIYqc2tHwL8a.png" alt=""></p>
<h1 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h1><p><strong>思维来自《统计学习方法》-李航</strong></p>
<p><img src="https://i.loli.net/2020/08/29/WElOzdbTy51o3RL.png" alt="">   </p>
<p><strong>凹脑图在线浏览地址：<a href="https://aonaotu.com/open/5b4da5f79360f80014dfd57e" target="_blank" rel="noopener">线性可分支持向量机</a></strong><br><font color = red><strong>才学疏浅，欢迎评论指导</strong></font></p>

      
    </div>
    
      
    
  </section>
</article>

          </div>
        
      
    
  </section>
  
    
      <br>
      <div class="prev-next">
        
        <p class="current">
          1 / 3
        </p>
        
          <a class="next" rel="next" href="/archives/2018/page/2/">
            <section class="post next white-box shadow">
              &nbsp;下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i>
            </section>
          </a>
        
      </div>
    
    <!-- 根据主题中的设置决定是否在archive中针对摘要部分的MathJax公式加载mathjax.js文件 -->
    
    

  


	
</div>
<aside class='l_side'>
  
  
    
    

<section class="widget blogger shadow desktop mobile">
  <div class='content'>
    
      
        <a class='avatar flat-box' href='/about/'>
          <img no-lazy src='https://i.loli.net/2020/07/11/p7e1WQKUfnClyxi.png'/>
        </a>
      
    
    
      <div class='text'>
        
        
        
          <p><span id="jinrishici-sentence">挖掘之家</span></p>
          <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
        
      </div>
    
    
      <div class="social-wrapper">
        
          
            <a href="/atom.xml"
              class="social fas fa-rss flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="mailto:me@xaoxuu.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/xaoxuu"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=63035382"
              class="social fas fa-headphones-alt flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

  

  
    
    
  

  <section class="widget category shadow desktop">
    
  <header>
    
      <a href='/blog/categories/'><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i><span class='name'>文章分类</span></a>
    
  </header>


    <div class='content'>
      <ul class="entry navigation">
        
          <li><a class="flat-box"
            title="/categories/NLP/" href="/categories/NLP/"
            id="categoriesNLP"
            ><div class='name'>NLP</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child"
            title="/categories/NLP/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/" href="/categories/NLP/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/"
            id="categoriesNLPE8AEBAE69687E7AE80E69E90"
            ><div class='name'>论文简析</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/Python/" href="/categories/Python/"
            id="categoriesPython"
            ><div class='name'>Python</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box child"
            title="/categories/Python/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" href="/categories/Python/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"
            id="categoriesPythonE695B0E68DAEE68C96E68E98"
            ><div class='name'>数据挖掘</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/"
            id="categoriesE3808AE7BB9FE8AEA1E5ADA6E4B9A0E696B9E6B395-E69D8EE888AAE3808B"
            ><div class='name'>《统计学习方法-李航》</div><div class='badge'>(13)</div></a></li>
        
          <li><a class="flat-box child"
            title="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA%E3%80%8B/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"
            id="categoriesE3808AE7BB9FE8AEA1E5ADA6E4B9A0E696B9E6B395-E69D8EE888AAE3808BE695B0E68DAEE68C96E68E98"
            ><div class='name'>数据挖掘</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/" href="/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"
            id="categoriesE59BBEE5838FE8AF86E588AB"
            ><div class='name'>图像识别</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child"
            title="/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/" href="/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/"
            id="categoriesE59BBEE5838FE8AF86E588ABE8AEBAE69687E7AE80E69E90"
            ><div class='name'>论文简析</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"
            id="categoriesE695B0E68DAEE68C96E68E98"
            ><div class='name'>数据挖掘</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"
            id="categoriesE69CBAE599A8E5ADA6E4B9A0"
            ><div class='name'>机器学习</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box"
            title="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"
            id="categoriesE6B7B1E5BAA6E5ADA6E4B9A0"
            ><div class='name'>深度学习</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child"
            title="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90/"
            id="categoriesE6B7B1E5BAA6E5ADA6E4B9A0E8AEBAE69687E7AE80E69E90"
            ><div class='name'>论文简析</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


  

  
    
    
  

  <section class="widget tagcloud shadow desktop mobile">
    
  <header>
    
      <a href='/blog/tags/'><i class="fas fa-tags fa-fw" aria-hidden="true"></i><span class='name'>热门标签</span></a>
    
  </header>


    <div class='content'>
      <a href="/tags/100%E5%A4%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%91%E6%88%98/" style="font-size: 14px; color: #999">100天机器学习挑战</a> <a href="/tags/K%E8%BF%91%E9%82%BB%E6%B3%95/" style="font-size: 14px; color: #999">K近邻法</a> <a href="/tags/SMO%E5%BA%8F%E5%88%97%E6%9C%80%E5%B0%8F%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" style="font-size: 14px; color: #999">SMO序列最小最优化算法</a> <a href="/tags/numpy/" style="font-size: 14px; color: #999">numpy</a> <a href="/tags/pandas/" style="font-size: 14px; color: #999">pandas</a> <a href="/tags/pyecharts/" style="font-size: 14px; color: #999">pyecharts</a> <a href="/tags/python/" style="font-size: 14px; color: #999">python</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 14px; color: #999">决策树</a> <a href="/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E6%A1%86%E6%9E%B6DeepEmo/" style="font-size: 24px; color: #555">情感分析框架DeepEmo</a> <a href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" style="font-size: 14px; color: #999">感知机</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8B%86%E5%88%86/" style="font-size: 14px; color: #999">数据拆分</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 14px; color: #999">数据挖掘</a> <a href="/tags/%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" style="font-size: 14px; color: #999">最优化算法</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" style="font-size: 14px; color: #999">最大熵模型</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/" style="font-size: 14px; color: #999">朴素贝叶斯法</a> <a href="/tags/%E6%A0%B7%E6%9C%AC%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%8D%B7%E7%A7%AF%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81/" style="font-size: 24px; color: #555">样本自适应的在线卷积稀疏编码</a> <a href="/tags/%E6%A0%B8%E5%87%BD%E6%95%B0/" style="font-size: 14px; color: #999">核函数</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/" style="font-size: 14px; color: #999">模型的评估与选择</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14px; color: #999">深度学习</a> <a href="/tags/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/" style="font-size: 14px; color: #999">特征缩放</a> <a href="/tags/%E7%94%9F%E6%88%90%E5%99%A8/" style="font-size: 14px; color: #999">生成器</a> <a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E4%B8%89%E8%A6%81%E7%B4%A0/" style="font-size: 14px; color: #999">监督学习与统计学习三要素</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 14px; color: #999">线性可分支持向量机</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 14px; color: #999">线性支持向量机</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" style="font-size: 14px; color: #999">统计学习概论</a> <a href="/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/" style="font-size: 14px; color: #999">迭代器</a> <a href="/tags/%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" style="font-size: 14px; color: #999">逻辑斯蒂回归模型</a> <a href="/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 14px; color: #999">非线性支持向量机</a>
    </div>
  </section>


  

  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js
      theme='#1BCDFC'
      autoplay='false'
      volume='0.7'
      loop='all'
      order='list'
      fixed='false'
      list-max-height='340px'
      server='netease'
      type='playlist'
      id='3175833810'
      list-folded='true'>
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="/atom.xml"
                class="social fas fa-rss flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="mailto:me@xaoxuu.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://github.com/xaoxuu"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://music.163.com/#/user/home?id=63035382"
                class="social fas fa-headphones-alt flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://volantis.js.org/" target="_blank" class="codename">Volantis</a>
        作为主题，总访问量为
          <span id="busuanzi_value_site_pv"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
          次
        
      
    
      
        <div class='copyright'>
        <p><a href="https://xaoxuu.com" target="_blank" rel="noopener">Copyright © 2017-2020 Mr. X</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>




	<!-- 根据主题中的设置决定是否在archive中针对摘要部分的MathJax公式加载mathjax.js文件 -->
	

	


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://i.loli.net/2020/07/11/ZBFRG8COa3PLnJ5.png"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  



  
    
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>

  
    
<script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>

  













  
<script src="/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>






<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>




  <script>setLoadingBarProgress(100);</script>
  <!--动态线条背景-->
  <script type="text/javascript"
    color="220,220,220" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
  </script>
</body>
</html>
